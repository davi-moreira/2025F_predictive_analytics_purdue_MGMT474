<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Professor: Davi Moreira">

<title> MGMT 47400: Predictive Analytics  – MGMT 47400: Predictive Analytics</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-278f079c28f28dbf8752571db94a6592.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-sidebar docked slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><span style="font-size: 100%;"> MGMT 47400: Predictive Analytics </span></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-center sidebar-header">
      <a href="../../index.html" class="sidebar-logo-link">
      <img src="../../images/mgmt_474_ai_logo_02-modified.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
      <div class="sidebar-tools-main">
    <a href="https://github.com/davi-moreira/2025F_predictive_analytics_purdue_MGMT474" title="GitHub" class="quarto-navigation-tool px-1" aria-label="GitHub"><i class="bi bi-github"></i></a>
</div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Home</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../syllabus.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Syllabus</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../schedule.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Schedule and Material</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#linear-model-selection-and-regularization" id="toc-linear-model-selection-and-regularization" class="nav-link" data-scroll-target="#linear-model-selection-and-regularization">Linear Model Selection and Regularization</a>
  <ul class="collapse">
  <li><a href="#linear-model-selection-and-regularization-1" id="toc-linear-model-selection-and-regularization-1" class="nav-link" data-scroll-target="#linear-model-selection-and-regularization-1">Linear Model Selection and Regularization</a></li>
  <li><a href="#in-praise-of-linear-models" id="toc-in-praise-of-linear-models" class="nav-link" data-scroll-target="#in-praise-of-linear-models">In praise of linear models!</a></li>
  <li><a href="#why-consider-alternatives-to-least-squares" id="toc-why-consider-alternatives-to-least-squares" class="nav-link" data-scroll-target="#why-consider-alternatives-to-least-squares">Why consider alternatives to least squares?</a></li>
  <li><a href="#three-classes-of-methods" id="toc-three-classes-of-methods" class="nav-link" data-scroll-target="#three-classes-of-methods">Three classes of methods</a></li>
  </ul></li>
  <li><a href="#subset-selection" id="toc-subset-selection" class="nav-link" data-scroll-target="#subset-selection">Subset Selection</a>
  <ul class="collapse">
  <li><a href="#best-subset-selection" id="toc-best-subset-selection" class="nav-link" data-scroll-target="#best-subset-selection">Best Subset Selection</a></li>
  <li><a href="#example---credit-data-set" id="toc-example---credit-data-set" class="nav-link" data-scroll-target="#example---credit-data-set">Example - Credit data set</a></li>
  <li><a href="#extensions-to-other-models" id="toc-extensions-to-other-models" class="nav-link" data-scroll-target="#extensions-to-other-models">Extensions to other models</a></li>
  </ul></li>
  <li><a href="#stepwise-selection" id="toc-stepwise-selection" class="nav-link" data-scroll-target="#stepwise-selection">Stepwise Selection</a>
  <ul class="collapse">
  <li><a href="#stepwise-selection-1" id="toc-stepwise-selection-1" class="nav-link" data-scroll-target="#stepwise-selection-1">Stepwise Selection</a></li>
  <li><a href="#forward-stepwise-selection" id="toc-forward-stepwise-selection" class="nav-link" data-scroll-target="#forward-stepwise-selection">Forward Stepwise Selection</a></li>
  <li><a href="#forward-stepwise-selection-in-detail" id="toc-forward-stepwise-selection-in-detail" class="nav-link" data-scroll-target="#forward-stepwise-selection-in-detail">Forward Stepwise Selection: In Detail</a></li>
  <li><a href="#credit-data-example" id="toc-credit-data-example" class="nav-link" data-scroll-target="#credit-data-example">Credit data example</a></li>
  <li><a href="#summary-forward-stepwise-selection" id="toc-summary-forward-stepwise-selection" class="nav-link" data-scroll-target="#summary-forward-stepwise-selection">Summary: Forward Stepwise Selection</a></li>
  </ul></li>
  <li><a href="#backward-stepwise-selection" id="toc-backward-stepwise-selection" class="nav-link" data-scroll-target="#backward-stepwise-selection">Backward Stepwise Selection</a>
  <ul class="collapse">
  <li><a href="#backward-stepwise-selection-1" id="toc-backward-stepwise-selection-1" class="nav-link" data-scroll-target="#backward-stepwise-selection-1">Backward Stepwise Selection</a></li>
  <li><a href="#backward-stepwise-selection-details" id="toc-backward-stepwise-selection-details" class="nav-link" data-scroll-target="#backward-stepwise-selection-details">Backward Stepwise Selection: details</a></li>
  <li><a href="#more-on-backward-stepwise-selection" id="toc-more-on-backward-stepwise-selection" class="nav-link" data-scroll-target="#more-on-backward-stepwise-selection">More on Backward Stepwise Selection</a></li>
  <li><a href="#summary-backward-stepwise-selection" id="toc-summary-backward-stepwise-selection" class="nav-link" data-scroll-target="#summary-backward-stepwise-selection">Summary: Backward Stepwise Selection</a></li>
  </ul></li>
  <li><a href="#choosing-the-optimal-model" id="toc-choosing-the-optimal-model" class="nav-link" data-scroll-target="#choosing-the-optimal-model">Choosing the Optimal Model</a>
  <ul class="collapse">
  <li><a href="#choosing-the-optimal-model-1" id="toc-choosing-the-optimal-model-1" class="nav-link" data-scroll-target="#choosing-the-optimal-model-1">Choosing the Optimal Model</a></li>
  <li><a href="#estimating-test-error-two-approaches" id="toc-estimating-test-error-two-approaches" class="nav-link" data-scroll-target="#estimating-test-error-two-approaches">Estimating test error: two approaches</a></li>
  </ul></li>
  <li><a href="#indirect-approaches" id="toc-indirect-approaches" class="nav-link" data-scroll-target="#indirect-approaches">Indirect Approaches</a>
  <ul class="collapse">
  <li><a href="#c_p-aic-bic-and-adjusted-r2" id="toc-c_p-aic-bic-and-adjusted-r2" class="nav-link" data-scroll-target="#c_p-aic-bic-and-adjusted-r2"><span class="math inline">\(C_p\)</span>, AIC, BIC, and Adjusted <span class="math inline">\(R^2\)</span></a></li>
  <li><a href="#mallows-c_p" id="toc-mallows-c_p" class="nav-link" data-scroll-target="#mallows-c_p">Mallows’ <span class="math inline">\(C_p\)</span></a></li>
  <li><a href="#aic" id="toc-aic" class="nav-link" data-scroll-target="#aic">AIC</a></li>
  <li><a href="#bic" id="toc-bic" class="nav-link" data-scroll-target="#bic">BIC</a></li>
  <li><a href="#adjusted-r2" id="toc-adjusted-r2" class="nav-link" data-scroll-target="#adjusted-r2">Adjusted <span class="math inline">\(R^2\)</span></a></li>
  <li><a href="#summary-c_p-aic-bic-and-adjusted-r-squared" id="toc-summary-c_p-aic-bic-and-adjusted-r-squared" class="nav-link" data-scroll-target="#summary-c_p-aic-bic-and-adjusted-r-squared">Summary: <span class="math inline">\(C_p\)</span>, AIC, BIC, and adjusted R-squared</a></li>
  </ul></li>
  <li><a href="#validation-and-cross-validation" id="toc-validation-and-cross-validation" class="nav-link" data-scroll-target="#validation-and-cross-validation">Validation and Cross-Validation</a>
  <ul class="collapse">
  <li><a href="#validation-and-cross-validation-1" id="toc-validation-and-cross-validation-1" class="nav-link" data-scroll-target="#validation-and-cross-validation-1">Validation and Cross-Validation</a></li>
  <li><a href="#credit-data-example-1" id="toc-credit-data-example-1" class="nav-link" data-scroll-target="#credit-data-example-1">Credit data example</a></li>
  <li><a href="#summary-validation-and-cross-validation" id="toc-summary-validation-and-cross-validation" class="nav-link" data-scroll-target="#summary-validation-and-cross-validation">Summary: Validation and Cross-validation</a></li>
  </ul></li>
  <li><a href="#shrinkage-methods" id="toc-shrinkage-methods" class="nav-link" data-scroll-target="#shrinkage-methods">Shrinkage Methods</a>
  <ul class="collapse">
  <li><a href="#shrinkage-methods-1" id="toc-shrinkage-methods-1" class="nav-link" data-scroll-target="#shrinkage-methods-1">Shrinkage Methods</a></li>
  </ul></li>
  <li><a href="#ridge-regression" id="toc-ridge-regression" class="nav-link" data-scroll-target="#ridge-regression">Ridge regression</a>
  <ul class="collapse">
  <li><a href="#ridge-regression-1" id="toc-ridge-regression-1" class="nav-link" data-scroll-target="#ridge-regression-1">Ridge regression</a></li>
  <li><a href="#ridge-regression-2" id="toc-ridge-regression-2" class="nav-link" data-scroll-target="#ridge-regression-2">Ridge regression</a></li>
  <li><a href="#credit-data-example-2" id="toc-credit-data-example-2" class="nav-link" data-scroll-target="#credit-data-example-2">Credit data example</a></li>
  <li><a href="#ridge-regression-scaling-of-predictors" id="toc-ridge-regression-scaling-of-predictors" class="nav-link" data-scroll-target="#ridge-regression-scaling-of-predictors">Ridge Regression: Scaling of Predictors</a></li>
  <li><a href="#why-does-ridge-regression-improve-over-least-squares" id="toc-why-does-ridge-regression-improve-over-least-squares" class="nav-link" data-scroll-target="#why-does-ridge-regression-improve-over-least-squares">Why Does Ridge Regression Improve Over Least Squares?</a></li>
  <li><a href="#summary-shrinkage-methods" id="toc-summary-shrinkage-methods" class="nav-link" data-scroll-target="#summary-shrinkage-methods">Summary: Shrinkage methods</a></li>
  </ul></li>
  <li><a href="#the-lasso" id="toc-the-lasso" class="nav-link" data-scroll-target="#the-lasso">The Lasso</a>
  <ul class="collapse">
  <li><a href="#the-lasso-1" id="toc-the-lasso-1" class="nav-link" data-scroll-target="#the-lasso-1">The Lasso</a></li>
  <li><a href="#the-lasso-2" id="toc-the-lasso-2" class="nav-link" data-scroll-target="#the-lasso-2">The Lasso</a></li>
  <li><a href="#example-credit-dataset" id="toc-example-credit-dataset" class="nav-link" data-scroll-target="#example-credit-dataset">Example: Credit Dataset</a></li>
  <li><a href="#the-variable-selection-property-of-the-lasso" id="toc-the-variable-selection-property-of-the-lasso" class="nav-link" data-scroll-target="#the-variable-selection-property-of-the-lasso">The Variable Selection Property of the Lasso</a></li>
  <li><a href="#the-lasso-and-ridge-picture" id="toc-the-lasso-and-ridge-picture" class="nav-link" data-scroll-target="#the-lasso-and-ridge-picture">The Lasso and Ridge Picture</a></li>
  <li><a href="#comparing-the-lasso-and-ridge-regression" id="toc-comparing-the-lasso-and-ridge-regression" class="nav-link" data-scroll-target="#comparing-the-lasso-and-ridge-regression">Comparing the Lasso and Ridge Regression</a></li>
  <li><a href="#comparing-the-lasso-and-ridge-regression-continued" id="toc-comparing-the-lasso-and-ridge-regression-continued" class="nav-link" data-scroll-target="#comparing-the-lasso-and-ridge-regression-continued">Comparing the Lasso and Ridge Regression: continued</a></li>
  <li><a href="#conclusions-about-ridge-and-lasso" id="toc-conclusions-about-ridge-and-lasso" class="nav-link" data-scroll-target="#conclusions-about-ridge-and-lasso">Conclusions about Ridge and Lasso</a></li>
  <li><a href="#summary-lasso" id="toc-summary-lasso" class="nav-link" data-scroll-target="#summary-lasso">Summary: Lasso</a></li>
  </ul></li>
  <li><a href="#selecting-the-tuning-parameter-for-ridge-regression-and-lasso" id="toc-selecting-the-tuning-parameter-for-ridge-regression-and-lasso" class="nav-link" data-scroll-target="#selecting-the-tuning-parameter-for-ridge-regression-and-lasso">Selecting the Tuning Parameter for Ridge Regression and Lasso</a>
  <ul class="collapse">
  <li><a href="#selecting-the-tuning-parameter-for-ridge-regression-and-lasso-1" id="toc-selecting-the-tuning-parameter-for-ridge-regression-and-lasso-1" class="nav-link" data-scroll-target="#selecting-the-tuning-parameter-for-ridge-regression-and-lasso-1">Selecting the Tuning Parameter for Ridge Regression and Lasso</a></li>
  <li><a href="#credit-data-example-3" id="toc-credit-data-example-3" class="nav-link" data-scroll-target="#credit-data-example-3">Credit data example</a></li>
  <li><a href="#simulated-data-example" id="toc-simulated-data-example" class="nav-link" data-scroll-target="#simulated-data-example">Simulated Data Example</a></li>
  <li><a href="#summary-selecting-the-tuning-parameter-lambda" id="toc-summary-selecting-the-tuning-parameter-lambda" class="nav-link" data-scroll-target="#summary-selecting-the-tuning-parameter-lambda">Summary: Selecting the tuning parameter (lambda)</a></li>
  </ul></li>
  <li><a href="#dimension-reduction-methods" id="toc-dimension-reduction-methods" class="nav-link" data-scroll-target="#dimension-reduction-methods">Dimension Reduction Methods</a>
  <ul class="collapse">
  <li><a href="#dimension-reduction-methods-1" id="toc-dimension-reduction-methods-1" class="nav-link" data-scroll-target="#dimension-reduction-methods-1">Dimension Reduction Methods</a></li>
  <li><a href="#dimension-reduction-methods-details" id="toc-dimension-reduction-methods-details" class="nav-link" data-scroll-target="#dimension-reduction-methods-details">Dimension Reduction Methods: Details</a></li>
  <li><a href="#dimension-reduction-methods-2" id="toc-dimension-reduction-methods-2" class="nav-link" data-scroll-target="#dimension-reduction-methods-2">Dimension Reduction Methods</a></li>
  <li><a href="#summary-dimension-reduction" id="toc-summary-dimension-reduction" class="nav-link" data-scroll-target="#summary-dimension-reduction">Summary: Dimension reduction</a></li>
  </ul></li>
  <li><a href="#principal-components-regression" id="toc-principal-components-regression" class="nav-link" data-scroll-target="#principal-components-regression">Principal Components Regression</a>
  <ul class="collapse">
  <li><a href="#principal-components-regression-1" id="toc-principal-components-regression-1" class="nav-link" data-scroll-target="#principal-components-regression-1">Principal Components Regression</a></li>
  <li><a href="#pictures-of-pca" id="toc-pictures-of-pca" class="nav-link" data-scroll-target="#pictures-of-pca">Pictures of PCA</a></li>
  <li><a href="#pictures-of-pca-1" id="toc-pictures-of-pca-1" class="nav-link" data-scroll-target="#pictures-of-pca-1">Pictures of PCA</a></li>
  <li><a href="#pictures-of-pca-2" id="toc-pictures-of-pca-2" class="nav-link" data-scroll-target="#pictures-of-pca-2">Pictures of PCA</a></li>
  <li><a href="#pictures-of-pca-3" id="toc-pictures-of-pca-3" class="nav-link" data-scroll-target="#pictures-of-pca-3">Pictures of PCA</a></li>
  <li><a href="#application-to-principal-components-regression" id="toc-application-to-principal-components-regression" class="nav-link" data-scroll-target="#application-to-principal-components-regression">Application to Principal Components Regression</a></li>
  <li><a href="#choosing-the-number-of-principal-component-directions-m" id="toc-choosing-the-number-of-principal-component-directions-m" class="nav-link" data-scroll-target="#choosing-the-number-of-principal-component-directions-m">Choosing the Number of Principal Component Directions <span class="math inline">\(M\)</span></a></li>
  </ul></li>
  <li><a href="#partial-least-squares-pls" id="toc-partial-least-squares-pls" class="nav-link" data-scroll-target="#partial-least-squares-pls">Partial Least Squares (PLS)</a>
  <ul class="collapse">
  <li><a href="#partial-least-squares-pls-1" id="toc-partial-least-squares-pls-1" class="nav-link" data-scroll-target="#partial-least-squares-pls-1">Partial Least Squares (PLS)</a></li>
  <li><a href="#partial-least-squares-pls-2" id="toc-partial-least-squares-pls-2" class="nav-link" data-scroll-target="#partial-least-squares-pls-2">Partial Least Squares (PLS)</a></li>
  <li><a href="#partial-least-squares-pls-details" id="toc-partial-least-squares-pls-details" class="nav-link" data-scroll-target="#partial-least-squares-pls-details">Partial Least Squares (PLS): Details</a></li>
  <li><a href="#summary-principal-components-regression-pcr" id="toc-summary-principal-components-regression-pcr" class="nav-link" data-scroll-target="#summary-principal-components-regression-pcr">Summary: Principal Components Regression (PCR)</a></li>
  </ul></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">Summary</a>
  <ul class="collapse">
  <li><a href="#summary-1" id="toc-summary-1" class="nav-link" data-scroll-target="#summary-1">Summary</a></li>
  </ul></li>
  <li><a href="#thank-you" id="toc-thank-you" class="nav-link" data-scroll-target="#thank-you">Thank you!</a></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="05_model_selection.html"><i class="bi bi-file-slides"></i>RevealJS</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span style="font-size: 100%;"> MGMT 47400: Predictive Analytics </span></h1>
<p class="subtitle lead"><span style="font-size: 150%;"> Model Selection and Regularization </span></p>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Professor: Davi Moreira </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<section id="overview" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="overview">Overview</h2>
<div class="nonincremental">
<div class="columns">
<div class="column" style="text-align: center; justify-content: center; align-items: center;">
<ul>
<li>Linear Model Selection and Regularization</li>
<li>Subset Selection</li>
<li>Stepwise Selection</li>
<li>Forward Stepwise Selection</li>
<li>Backward Stepwise Selection</li>
<li>Choosing the Optimal Model</li>
<li>Indirect Approaches</li>
<li>Validation and Cross-Validation</li>
</ul>
</div><div class="column" style="text-align: center; justify-content: center; align-items: center;">
<ul>
<li>Shrinkage Methods</li>
<li>Ridge Regression</li>
<li>The Lasso</li>
<li>Selecting the Tuning Parameter for Ridge Regression and Lasso</li>
<li>Dimension Reduction Methods</li>
<li>Principal Components Regression</li>
<li>Partial Least Squares (PLS)</li>
</ul>
</div>
</div>
</div>
<p><br></p>

<div class="no-row-height column-margin column-container"><div class="margin-aside">
<p><em>This lecture content is inspired by and replicates the material from <a href="https://www.statlearning.com/">An Introduction to Statistical Learning</a>.</em></p>
</div></div></section>
<section id="linear-model-selection-and-regularization" class="level1" data-background-color="#cfb991">
<h1 data-background-color="#cfb991">Linear Model Selection and Regularization</h1>
<section id="linear-model-selection-and-regularization-1" class="level2">
<h2 class="anchored" data-anchor-id="linear-model-selection-and-regularization-1">Linear Model Selection and Regularization</h2>
<p>Recall the linear model</p>
<p><span class="math display">\[
Y = \beta_0 + \beta_1 X_1 + \cdots + \beta_p X_p + \epsilon.
\]</span></p>
<ul>
<li><p>In the lectures that follow, we consider some approaches for extending the linear model framework. We will generalize the linear model in order to accommodate <em>non-linear</em>, but still <em>additive</em>, relationships.</p></li>
<li><p>In the lectures covering Chapter 8, we consider even more general <em>non-linear</em> models.</p></li>
</ul>
</section>
<section id="in-praise-of-linear-models" class="level2">
<h2 class="anchored" data-anchor-id="in-praise-of-linear-models">In praise of linear models!</h2>
<ul>
<li><p>Despite its simplicity, the linear model has distinct advantages in terms of its <em>interpretability</em> and often shows good <em>predictive performance</em>.</p></li>
<li><p>Hence we discuss in this lecture some ways in which the simple linear model can be improved, by replacing ordinary least squares fitting with some alternative fitting procedures.</p></li>
</ul>
</section>
<section id="why-consider-alternatives-to-least-squares" class="level2">
<h2 class="anchored" data-anchor-id="why-consider-alternatives-to-least-squares">Why consider alternatives to least squares?</h2>
<ul>
<li><p><strong>Prediction Accuracy</strong>: especially when <span class="math inline">\(p &gt; n\)</span>, to control the variance.</p></li>
<li><p><strong>Model Interpretability</strong>: By removing irrelevant features — that is, by setting the corresponding coefficient estimates to zero — we can obtain a model that is more easily interpreted. We will present some approaches for automatically performing <em>feature selection</em>.</p></li>
</ul>
</section>
<section id="three-classes-of-methods" class="level2">
<h2 class="anchored" data-anchor-id="three-classes-of-methods">Three classes of methods</h2>
<ul>
<li><p><strong>Subset Selection</strong>. We identify a subset of the <span class="math inline">\(p\)</span> predictors that we believe to be related to the response. We then fit a model using least squares on the reduced set of variables.<em>Best Subset Selection</em>, <em>Foward Selection</em>, and <em>Backwards Selection</em> are the main techniques here.</p></li>
<li><p><strong>Shrinkage</strong>. We fit a model involving all <span class="math inline">\(p\)</span> predictors, but the estimated coefficients are shrunken towards zero relative to the least squares estimates. This shrinkage (also known as <em>regularization</em>) has the effect of reducing variance and can also perform variable selection. <em>Ridge Regression</em> and <em>Lasso</em> are the main techniques here.</p></li>
<li><p><strong>Dimension Reduction</strong>. We project the <span class="math inline">\(p\)</span> predictors into a <span class="math inline">\(M\)</span>-dimensional subspace, where <span class="math inline">\(M &lt; p\)</span>. This is achieved by computing <span class="math inline">\(M\)</span> different <em>linear combinations</em>, or <em>projections</em>, of the variables. Then these <span class="math inline">\(M\)</span> projections are used as predictors to fit a linear regression model by least squares. <em>Principal Components Regression</em> and <em>Partial Least Squares</em> are the main techniques here.</p></li>
</ul>
</section>
</section>
<section id="subset-selection" class="level1" data-background-color="#cfb991">
<h1 data-background-color="#cfb991">Subset Selection</h1>
<section id="best-subset-selection" class="level2">
<h2 class="anchored" data-anchor-id="best-subset-selection">Best Subset Selection</h2>
<div style="font-size: 80%;">
<p>The core idea is to identify a simpler model that includes only a subset of the <span class="math inline">\(P\)</span> available predictors, thereby improving interpretability and potentially enhancing predictive performance.</p>
<p>To implement best subset selection systematically, we consider every possible combination of predictors and evaluate each resulting model. The process begins with the <strong>null model</strong> (<span class="math inline">\(M_0\)</span>), which includes no predictors and only an intercept, meaning it predicts the sample mean for all observations. From there, models are incrementally built by incorporating different subsets of predictors, ultimately selecting the model that optimally balances predictive accuracy and complexity. Here are the steps:</p>
<ol type="1">
<li><p>Let <span class="math inline">\(\mathcal{M}_0\)</span> denote the <em>null model</em>, which contains no predictors. This model simply predicts the sample mean for each observation.</p></li>
<li><p>For <span class="math inline">\(k = 1, 2, \ldots, p\)</span>:</p>
<ul>
<li><p>Fit all <span class="math inline">\(\binom{p}{k}\)</span> models, “<span class="math inline">\(p\)</span> choose <span class="math inline">\(k\)</span> models”, that contain exactly <span class="math inline">\(k\)</span> predictors. <span class="math inline">\(\binom{p}{k} = \frac{p!}{k!(p-k)!}\)</span></p></li>
<li><p>Pick the best among these <span class="math inline">\(\binom{p}{k}\)</span> models, and call it <span class="math inline">\(\mathcal{M}_k\)</span>. Here <em>best</em> is defined as having the smallest Residual Sum of Squares (RSS), or equivalently the largest <span class="math inline">\(R^2\)</span>.</p></li>
</ul></li>
<li><p>Select a single best model from among <span class="math inline">\(\mathcal{M}_0, \ldots, \mathcal{M}_p\)</span> using cross-validated prediction error, <span class="math inline">\(C_p\)</span> (AIC), BIC, or adjusted <span class="math inline">\(R^2\)</span>. The goal is to choose the model with the smallest test error, not the smallest training error.</p></li>
</ol>
</div>
</section>
<section id="example---credit-data-set" class="level2">
<h2 class="anchored" data-anchor-id="example---credit-data-set">Example - Credit data set</h2>
<div style="font-size: 70%;">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figs/6_1-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:55.0%"></p>
</figure>
</div>
</div>
</div>
<ul>
<li><p>For each possible model containing a subset of the ten predictors in the <em>Credit</em> data set, the Residual Sum of Squares (RSS) and <span class="math inline">\(R^2\)</span> are displayed. The red frontier tracks the <em>best</em> model for a given number of predictors, according to RSS and <span class="math inline">\(R^2\)</span>.</p></li>
<li><p>Though the data set contains only ten predictors, the x-axis ranges from 1 to 11, since one of the variables is categorical and takes on three values, leading to the creation of two dummy variables.</p></li>
<li><p>The reason that there’s a lot of dots in this picture is because there’s a lot of possible sub models given 10 total predictors. We have <span class="math inline">\(2^{p} = 2^{10}\approx 1,000\)</span> subsets.</p></li>
<li><p>The number <span class="math inline">\(2^p\)</span> arises because each predictor (out of <span class="math inline">\(p\)</span> predictors) can either be <strong>included</strong> or <strong>excluded</strong> from a subset model. This binary decision for each predictor gives <span class="math inline">\(2\)</span> choices (include or exclude). When there are <span class="math inline">\(p\)</span> predictors, the total number of possible subsets (or models) is calculated as <span class="math inline">\(2^p\)</span>.</p></li>
</ul>
</div>
</section>
<section id="extensions-to-other-models" class="level2">
<h2 class="anchored" data-anchor-id="extensions-to-other-models">Extensions to other models</h2>
<div class="nonincremental">
<div style="font-size: 80%;">
<ul>
<li><p>The same ideas apply to other types of models, such as logistic regression.</p></li>
<li><p>When dealing with other type of models, instead of the RSS, we look into the <strong>deviance</strong> (D), which is commonly used in generalized linear models. The deviance is calculated as:</p></li>
</ul>
<p><span class="math display">\[
D = -2 \cdot \log L_{\text{max}}
\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(D\)</span> is the deviance,</li>
<li><span class="math inline">\(\log L_{\text{max}}\)</span> is the maximized log-likelihood of the model.</li>
</ul>
<p>This formula allows the deviance to serve as a measure of goodness of fit, analogous to the residual sum of squares (RSS) in linear regression, but applicable to a broader class of models.</p>
</div>
</div>
</section>
</section>
<section id="stepwise-selection" class="level1" data-background-color="#cfb991">
<h1 data-background-color="#cfb991">Stepwise Selection</h1>
<section id="stepwise-selection-1" class="level2">
<h2 class="anchored" data-anchor-id="stepwise-selection-1">Stepwise Selection</h2>
<ul>
<li><p>For computational reasons, best subset selection cannot be applied with very large <span class="math inline">\(p\)</span>.</p></li>
<li><p>Best subset selection may also suffer from statistical problems when <span class="math inline">\(p\)</span> is large: larger the search space, the higher the chance of finding models that look good on the training data, even though they might not have any predictive power on future data.</p></li>
<li><p>Thus an enormous search space can lead to <strong>overfitting</strong> and high variance of the coefficient estimates. For the authors of the book, it is not recommended to use the <em>best subset</em> approach if you have more than 20 predictors.</p></li>
<li><p>For both of these reasons, <strong>stepwise</strong> methods, which explore a far more restricted set of models (<span class="math inline">\(p^2\)</span>), are attractive alternatives to best subset selection.</p></li>
</ul>
</section>
<section id="forward-stepwise-selection" class="level2">
<h2 class="anchored" data-anchor-id="forward-stepwise-selection">Forward Stepwise Selection</h2>
<ul>
<li><p>Forward stepwise selection begins with a model containing no predictors, and then adds predictors to the model, one-at-a-time, until all of the predictors are in the model.</p></li>
<li><p>In particular, at each step the variable that gives the greatest <em>additional</em> improvement to the fit is added to the model.</p></li>
</ul>
</section>
<section id="forward-stepwise-selection-in-detail" class="level2">
<h2 class="anchored" data-anchor-id="forward-stepwise-selection-in-detail">Forward Stepwise Selection: In Detail</h2>
<div class="nonincremental">
<div style="font-size: 80%;">
<ol type="1">
<li><p>Let <span class="math inline">\(\mathcal{M}_0\)</span> denote the <em>null model</em>, which contains no predictors.</p></li>
<li><p>For <span class="math inline">\(k = 0, \ldots, p - 1\)</span>:</p>
<ul>
<li><p>2.1 Consider all <span class="math inline">\(p - k\)</span> models that augment the predictors in <span class="math inline">\(\mathcal{M}_k\)</span> with one additional predictor. This is different from what we were doing in in the best subset selection case. Here do not look at every possible model containing <span class="math inline">\(p\)</span> predictors. Instead, we are just looking at every possible model that contains one more predictor than <span class="math inline">\(M_{k-1}\)</span>.</p></li>
<li><p>2.2 Choose the <em>best</em> among these <span class="math inline">\(p - k\)</span> models, and call it <span class="math inline">\(\mathcal{M}_{k+1}\)</span>. Here <em>best</em> is defined as having smallest RSS or highest <span class="math inline">\(R^2\)</span>.</p></li>
</ul></li>
<li><p>Select a single best model from among <span class="math inline">\(\mathcal{M}_0, \ldots, \mathcal{M}_p\)</span> using cross-validated prediction error, <span class="math inline">\(C_p\)</span> (AIC), BIC, or adjusted <span class="math inline">\(R^2\)</span>.</p></li>
</ol>
<ul>
<li>Forward Stepwise Selection presents computational advantage over best subset selection. The total number of models evaluated is the sum of the sequence:</li>
</ul>
<p><span class="math display">\[
p + (p - 1) + (p - 2) + \dots + 1 = \frac{p(p + 1)}{2}
\]</span></p>
<ul>
<li><p>For large <span class="math inline">\(p\)</span>, the term <span class="math inline">\(\frac{p(p + 1)}{2}\)</span> is dominated by <span class="math inline">\(\frac{p^2}{2}\)</span>. Thus, the computational cost is approximately proportional to <span class="math inline">\(p^2\)</span>.</p></li>
<li><p>It is not guaranteed to find the best possible model out of all <span class="math inline">\(2^p\)</span> models containing subsets of the <span class="math inline">\(p\)</span> predictors.</p></li>
</ul>
</div>
</div>
</section>
<section id="credit-data-example" class="level2">
<h2 class="anchored" data-anchor-id="credit-data-example">Credit data example</h2>
<p>The first four selected models for best subset selection and forward stepwise selection on the Credit data set.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 34%">
<col style="width: 40%">
</colgroup>
<thead>
<tr class="header">
<th># Variables</th>
<th>Best subset</th>
<th>Forward stepwise</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>One</td>
<td><em>rating</em></td>
<td><em>rating</em></td>
</tr>
<tr class="even">
<td>Two</td>
<td><em>rating, income</em></td>
<td><em>rating, income</em></td>
</tr>
<tr class="odd">
<td>Three</td>
<td><em>rating, income, student</em></td>
<td><em>rating, income, student</em></td>
</tr>
<tr class="even">
<td>Four</td>
<td><em>cards, income, student, limit</em></td>
<td><em>rating, income, student, limit</em></td>
</tr>
</tbody>
</table>
<p>The first three models are identical but the fourth models differ.</p>
<p>This discrepancy happens because there is correlation between features.</p>
</section>
<section id="summary-forward-stepwise-selection" class="level2">
<h2 class="anchored" data-anchor-id="summary-forward-stepwise-selection">Summary: Forward Stepwise Selection</h2>
<div class="nonincremental">
<div style="font-size: 60%;">
<p>Stepwise selection is a computationally efficient alternative to best subset selection in model building, especially with large predictor sets.</p>
<div class="columns">
<div class="column" style="width:45%;">
<section id="highlights" class="level3">
<h3 class="anchored" data-anchor-id="highlights"><strong>Highlights</strong></h3>
<ul>
<li>Stepwise selection offers a practical approach for model selection.</li>
<li>Best subset selection can lead to overfitting, especially with many predictors.</li>
<li>Forward stepwise selection considers fewer models than best subset, making it computationally efficient.</li>
<li>Deviance generalizes residual sum of squares across various models.</li>
<li>Best subset selection becomes impractical beyond 30-40 predictors due to computational limits.</li>
<li>Forward stepwise may not always find the optimal model compared to best subset.</li>
<li>Correlation between features impacts model selection outcomes between methods.</li>
</ul>
</section>
</div><div class="column" style="width:55%;">
<section id="key-insights" class="level3">
<h3 class="anchored" data-anchor-id="key-insights"><strong>Key Insights</strong></h3>
<ul>
<li><p><strong>Computational Efficiency</strong>: Stepwise selection significantly reduces the number of models evaluated, making it feasible for larger datasets. This is essential in modern data analysis, where predictors can number in the thousands.</p></li>
<li><p><strong>Overfitting Risks</strong>: With best subset selection, the risk of overfitting increases as the number of predictors grows, which can lead to poor performance on unseen data. This highlights the importance of model validation techniques.</p></li>
<li><p><strong>Model Nesting</strong>: Forward stepwise selection builds models incrementally, ensuring that each new model is a superset of the previous one, which helps maintain a streamlined search process for the best predictors.</p></li>
<li><p><strong>Deviance vs.&nbsp;RSS</strong>: Understanding the difference in metrics like deviance and residual sum of squares is crucial for accurately assessing model fit across various types of regression analyses.</p></li>
<li><p><strong>Practical Limits</strong>: Most statistical packages struggle with subset selection beyond 30-40 predictors, indicating the need for streamlined methods like stepwise selection in high-dimensional contexts.</p></li>
<li><p><strong>Model Comparison</strong>: Forward stepwise selection may yield different models than best subset selection, emphasizing the need for careful evaluation of model performance on independent datasets.</p></li>
<li><p><strong>Correlation Effects</strong>: The discrepancies between the two methods arise from correlations among predictors, showcasing the intricate dynamics of variable selection in regression modeling.</p></li>
</ul>
</section>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="backward-stepwise-selection" class="level1" data-background-color="#cfb991">
<h1 data-background-color="#cfb991">Backward Stepwise Selection</h1>
<section id="backward-stepwise-selection-1" class="level2">
<h2 class="anchored" data-anchor-id="backward-stepwise-selection-1">Backward Stepwise Selection</h2>
<ul>
<li><p>Like forward stepwise selection, <em>backward stepwise selection</em> provides an efficient alternative to best subset selection.</p></li>
<li><p>However, unlike forward stepwise selection, it begins with the full least squares model containing all <span class="math inline">\(p\)</span> predictors, and then iteratively removes the least useful predictor, one-at-a-time.</p></li>
</ul>
</section>
<section id="backward-stepwise-selection-details" class="level2">
<h2 class="anchored" data-anchor-id="backward-stepwise-selection-details">Backward Stepwise Selection: details</h2>
<ol type="1">
<li><p>Let <span class="math inline">\(\mathcal{M}_p\)</span> denote the <em>full model</em>, which contains all <span class="math inline">\(p\)</span> predictors.</p></li>
<li><p>For <span class="math inline">\(k = p, p - 1, \ldots, 1\)</span>:</p>
<ul>
<li><p>2.1 Consider all <span class="math inline">\(k\)</span> models that contain all but one of the predictors in <span class="math inline">\(\mathcal{M}_k\)</span>, for a total of <span class="math inline">\(k - 1\)</span> predictors.</p></li>
<li><p>2.2 Choose the <em>best</em> among these <span class="math inline">\(k\)</span> models, and call it <span class="math inline">\(\mathcal{M}_{k-1}\)</span>. Here <em>best</em> is defined as having smallest RSS or highest <span class="math inline">\(R^2\)</span>.</p></li>
</ul></li>
<li><p>Select a single best model from among <span class="math inline">\(\mathcal{M}_0, \ldots, \mathcal{M}_p\)</span> using cross-validated prediction error, <span class="math inline">\(C_p\)</span> (AIC), BIC, or adjusted <span class="math inline">\(R^2\)</span>.</p></li>
</ol>
</section>
<section id="more-on-backward-stepwise-selection" class="level2">
<h2 class="anchored" data-anchor-id="more-on-backward-stepwise-selection">More on Backward Stepwise Selection</h2>
<ul>
<li><p>Like forward stepwise selection, the backward selection approach searches through only <span class="math inline">\(1 + p(p+1)/2\)</span> models, and so can be applied in settings where <span class="math inline">\(p\)</span> is too large to apply best subset selection.</p></li>
<li><p>Like forward stepwise selection, backward stepwise selection is not guaranteed to yield the <em>best</em> model containing a subset of the <span class="math inline">\(p\)</span> predictors.</p></li>
<li><p>Backward selection requires that the <strong>number of samples</strong> <span class="math inline">\(n\)</span> is larger than the number of variables <span class="math inline">\(p\)</span> (so that the full model can be fit). In contrast, forward stepwise can be used even when <span class="math inline">\(n &lt; p\)</span>, and so is the only viable subset method when <span class="math inline">\(p\)</span> is very large.</p></li>
</ul>
</section>
<section id="summary-backward-stepwise-selection" class="level2">
<h2 class="anchored" data-anchor-id="summary-backward-stepwise-selection">Summary: Backward Stepwise Selection</h2>
<div class="nonincremental">
<div style="font-size: 60%;">
<p>Backward stepwise selection removes predictors from a full model to improve efficiency in model selection, contrasting with forward stepwise selection.</p>
<div class="columns">
<div class="column" style="width:45%;">
<section id="highlights-1" class="level3">
<h3 class="anchored" data-anchor-id="highlights-1"><strong>Highlights</strong></h3>
<ul>
<li>Backward stepwise starts with a full model (<span class="math inline">\(M_p\)</span>) and removes predictors one at a time.</li>
<li>It evaluates the least useful predictor to minimize impact on model fit.</li>
<li>This method is computationally efficient, considering around <span class="math inline">\(p^2/2\)</span>models.</li>
<li>Only applicable when the number of observations (<span class="math inline">\(n\)</span>) is greater than the number of predictors.</li>
<li><span class="math inline">\(R^2\)</span>and RSS might mislead model selection, focusing on training error rather than test error.</li>
<li>Cross-validation, AIC, BIC, or adjusted <span class="math inline">\(R^2\)</span>should guide the final model choice.</li>
<li>Backward and forward selections are not guaranteed to find the best model but can yield good test set results.</li>
</ul>
</section>
</div><div class="column" style="width:55%;">
<section id="key-insights-1" class="level3">
<h3 class="anchored" data-anchor-id="key-insights-1"><strong>Key Insights</strong></h3>
<ul>
<li><p><strong>Methodology Contrast</strong>: Backward stepwise selection is an efficient alternative to forward selection, emphasizing the removal of predictors rather than their addition. This reversal highlights different strategies in model optimization.</p></li>
<li><p><strong>Model Evaluation</strong>: The approach assesses the least impactful predictors, ensuring that model performance remains stable as predictors are eliminated, which is crucial for maintaining predictive accuracy.</p></li>
<li><p><strong>Computational Efficiency</strong>: Backward stepwise selection dramatically reduces computational load compared to best subset selection, making it a suitable option for larger datasets.</p></li>
<li><p><strong>Observational Requirement</strong>: This method necessitates that the number of observations is greater than the number of predictors, ensuring that a least squares model can be appropriately fitted, which is a critical consideration in practical applications.</p></li>
<li><p><strong>Training vs.&nbsp;Test Error</strong>: Relying solely on training error metrics like RSS and <span class="math inline">\(R^2\)</span>can lead to overfitting, indicating the need for broader evaluation methods to predict future performance.</p></li>
<li><p><strong>Model Selection Techniques</strong>: Utilizing techniques like cross-validation, AIC, or BIC for model selection can help mitigate the risks associated with simply opting for models with the best training error.</p></li>
<li><p><strong>Outcome Consistency</strong>: While backward stepwise may not find the absolute best model, it can produce models that perform well on unseen data, demonstrating its practical utility in predictive modeling.</p></li>
</ul>
</section>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="choosing-the-optimal-model" class="level1" data-background-color="#cfb991">
<h1 data-background-color="#cfb991">Choosing the Optimal Model</h1>
<section id="choosing-the-optimal-model-1" class="level2">
<h2 class="anchored" data-anchor-id="choosing-the-optimal-model-1">Choosing the Optimal Model</h2>
<ul>
<li><p>The model containing all of the predictors will always have the smallest RSS and the largest <span class="math inline">\(R^2\)</span>, since these quantities are related to the training error.</p></li>
<li><p><strong>We wish to choose a model with low test error</strong>, not a model with low training error. Recall that training error is usually a poor estimate of test error.</p></li>
<li><p>Therefore, RSS and <span class="math inline">\(R^2\)</span> are not suitable for selecting the best model among a collection of models with different numbers of predictors.</p></li>
</ul>
</section>
<section id="estimating-test-error-two-approaches" class="level2">
<h2 class="anchored" data-anchor-id="estimating-test-error-two-approaches">Estimating test error: two approaches</h2>
<ul>
<li><p>Indirect: We can indirectly estimate test error by making an <em>adjustment</em> to the training error to account for the bias due to overfitting.</p></li>
<li><p>Direct: We can <em>directly</em> estimate the test error, using either a validation set approach or a cross-validation approach, as discussed in previous lectures.</p></li>
</ul>
</section>
</section>
<section id="indirect-approaches" class="level1" data-background-color="#cfb991">
<h1 data-background-color="#cfb991">Indirect Approaches</h1>
<section id="c_p-aic-bic-and-adjusted-r2" class="level2">
<h2 class="anchored" data-anchor-id="c_p-aic-bic-and-adjusted-r2"><span class="math inline">\(C_p\)</span>, AIC, BIC, and Adjusted <span class="math inline">\(R^2\)</span></h2>
<p>These techniques adjust the training error for the model size, and can be used to select among a set of models with different numbers of variables.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figs/6_2-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:65.0%"></p>
</figure>
</div>
</div>
</div>
<p>The figure displays <span class="math inline">\(C_p\)</span>, BIC, and adjusted <span class="math inline">\(R^2\)</span> for the best model of each size produced by best subset selection on the <em>Credit</em> data set.</p>
<ul>
<li>It suggests that we must choose a model with 4 to 6 predictors.</li>
<li>The main recommmendation is to keep the model as simple as possible. By identifying that the values do not change too much as we increase the number of predictors, a model with 4 predictors will be recommended.</li>
</ul>
</section>
<section id="mallows-c_p" class="level2">
<h2 class="anchored" data-anchor-id="mallows-c_p">Mallows’ <span class="math inline">\(C_p\)</span></h2>
<div class="nonincremental">
<div style="font-size: 80%;">
<p>Mallows’ <span class="math inline">\(C_p\)</span> balances <strong>model fit</strong> and <strong>model complexity</strong>:</p>
<p><span class="math display">\[
C_p = \frac{1}{n} \left( \text{RSS} + 2d\hat{\sigma}^2 \right)
\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(d\)</span>: Total number of parameters used in the model (including the intercept).<br>
</li>
<li><span class="math inline">\(\hat{\sigma}^2\)</span>: Estimate of the error variance <span class="math inline">\(\epsilon\)</span>, associated with each response measurement.<br>
</li>
<li><span class="math inline">\(\text{RSS}\)</span>: Residual Sum of Squares, measuring the error between observed and predicted values.<br>
</li>
<li><span class="math inline">\(n\)</span>: Number of observations in the dataset.</li>
</ul>
<p><strong>Explanation</strong></p>
<ul>
<li>The <span class="math inline">\(\text{RSS}\)</span> measures the fit.</li>
<li>The penalty term <span class="math inline">\(2d\hat{\sigma}^2\)</span> discourages overfitting.</li>
</ul>
<p><strong>Decision</strong>: The lowest, the better!</p>
</div>
</div>
</section>
<section id="aic" class="level2">
<h2 class="anchored" data-anchor-id="aic">AIC</h2>
<p>The <em>Akaike Information Criteria (AIC)</em> criterion is defined for a large class of models fit by maximum likelihood:</p>
<p><span class="math display">\[
  \text{AIC} = -2 \log L + 2 \cdot d,
\]</span></p>
<p>where <span class="math inline">\(L\)</span> is the maximized value of the likelihood function for the estimated model.</p>
<ul>
<li>In the case of the linear model, <span class="math inline">\(-2 \log L = \frac{RSS}{\sigma^2}\)</span></li>
<li>In the case of the linear model with Gaussian errors, maximum likelihood and least squares are the same thing, and <span class="math inline">\(C_p\)</span> and AIC are equivalent.</li>
<li>AIC and Mallow’s <span class="math inline">\(C_p\)</span> are proportional to each other.</li>
<li>AIC is a good approach for non-linear models, e.g.&nbsp;logistic regression.</li>
</ul>
</section>
<section id="bic" class="level2">
<h2 class="anchored" data-anchor-id="bic">BIC</h2>
<p>This is the <em>Bayesian Information Criterion (BIC)</em>:</p>
<p><span class="math display">\[
\text{BIC} = \frac{1}{n} \left( \text{RSS} + \log(n)d\hat{\sigma}^2 \right).
\]</span></p>
<ul>
<li><p>Like <span class="math inline">\(C_p\)</span>, the BIC will tend to take on a small value for a model with a low test error, and so generally we select the model that has the lowest BIC value.</p></li>
<li><p>Notice that BIC replaces the <span class="math inline">\(2d\hat{\sigma}^2\)</span> used by <span class="math inline">\(C_p\)</span> with a <span class="math inline">\(\log(n)d\hat{\sigma}^2\)</span> term, where <span class="math inline">\(n\)</span> is the number of observations.</p></li>
<li><p>Since <span class="math inline">\(\log n &gt; 2\)</span> for any <span class="math inline">\(n &gt; 7\)</span>, the BIC statistic generally places a heavier penalty on models with many variables, and hence results in the selection of smaller models than <span class="math inline">\(C_p\)</span> or AIC.</p></li>
</ul>
</section>
<section id="adjusted-r2" class="level2">
<h2 class="anchored" data-anchor-id="adjusted-r2">Adjusted <span class="math inline">\(R^2\)</span></h2>
<p>For a least squares model with <span class="math inline">\(d\)</span> variables, the adjusted <span class="math inline">\(R^2\)</span> statistic is calculated as</p>
<p><span class="math display">\[
    \text{Adjusted } R^2 = 1 - \frac{\text{RSS}/(n - d - 1)}{\text{TSS}/(n - 1)}.
\]</span></p>
<p>where TSS is the total sum of squares, <span class="math inline">\(TSS = \Sigma_i^n(y_i - \bar{y})^2\)</span>.</p>
<ul>
<li><p>Unlike <span class="math inline">\(C_p\)</span>, AIC, and BIC, for which a <em>small</em> value indicates a model with a low test error, a <em>large</em> value of adjusted <span class="math inline">\(R^2\)</span> indicates a model with a small test error.</p></li>
<li><p>Maximizing the adjusted <span class="math inline">\(R^2\)</span> is equivalent to minimizing <span class="math inline">\(\frac{\text{RSS}}{n - d - 1}\)</span>. While RSS always decreases as the number of variables in the model increases, <span class="math inline">\(\frac{\text{RSS}}{n - d - 1}\)</span> may increase or decrease, due to the presence of <span class="math inline">\(d\)</span> in the denominator.</p></li>
<li><p>Unlike the <span class="math inline">\(R^2\)</span> statistic, the adjusted <span class="math inline">\(R^2\)</span> statistic <em>pays a price</em> for the inclusion of unnecessary variables in the model.</p></li>
</ul>
</section>
<section id="summary-c_p-aic-bic-and-adjusted-r-squared" class="level2">
<h2 class="anchored" data-anchor-id="summary-c_p-aic-bic-and-adjusted-r-squared">Summary: <span class="math inline">\(C_p\)</span>, AIC, BIC, and adjusted R-squared</h2>
<div class="nonincremental">
<div style="font-size: 60%;">
<p>Estimating test error for models involves adjusting training error or using direct methods like cross-validation. Tools like CP, AIC, BIC, and adjusted R-squared help select optimal models.</p>
<div class="columns">
<div class="column" style="width:45%;">
<section id="highlights-2" class="level3">
<h3 class="anchored" data-anchor-id="highlights-2"><strong>Highlights</strong></h3>
<ul>
<li>Estimating test error is crucial for model selection.</li>
<li>Two approaches: indirect adjustment of training error and direct estimation methods.</li>
<li><span class="math inline">\(C_p\)</span>, AIC, BIC, and adjusted <span class="math inline">\(R^2\)</span> help model comparison.</li>
<li>A model should minimize <span class="math inline">\(C_p\)</span> and BIC while maximizing adjusted <span class="math inline">\(R^2\)</span>.</li>
<li>Adjusted <span class="math inline">\(R^2\)</span> allows meaningful comparisons across different models.</li>
<li>Cross-validation is versatile and can be applied to various models.</li>
<li>Simplicity is favored; fewer predictors often yield better results.</li>
</ul>
</section>
</div><div class="column" style="width:55%;">
<section id="key-insights-2" class="level3">
<h3 class="anchored" data-anchor-id="key-insights-2"><strong>Key Insights</strong></h3>
<ul>
<li><p><strong>Test Error Estimation</strong>: Accurate test error estimation is vital for model evaluation. It helps choose the best model among multiple options, ensuring reliability in predictions.</p></li>
<li><p><strong>Indirect vs.&nbsp;Direct Methods</strong>: Understanding both indirect (adjusting training error) and direct (cross-validation) methods provides flexibility in model evaluation, catering to different scenarios in data analysis.</p></li>
<li><p><strong>Model Selection Criteria</strong>: <span class="math inline">\(C_p\)</span>, AIC, BIC, and adjusted <span class="math inline">\(R^2\)</span> serve as essential criteria for model selection. They help quantify model performance and complexity, aiding in decision-making.</p></li>
<li><p><strong>Minimizing</strong> <span class="math inline">\(C_p\)</span> and BIC: Aiming for lower <span class="math inline">\(C_p\)</span> and BIC values suggests a more parsimonious model, which is often preferred for its simplicity and interpretability while still capturing the necessary relationships.</p></li>
<li><p><strong>Cross-Validation Versatility</strong>: Cross-validation is a powerful tool applicable to a wide range of models, including non-linear ones, making it a preferred method for estimating test error in various contexts.</p></li>
<li><p><strong>Adjusted</strong> <span class="math inline">\(R^2\)</span> Utility: Unlike traditional <span class="math inline">\(R^2\)</span>, adjusted <span class="math inline">\(R^2\)</span> provides a way to compare models with differing numbers of predictors, addressing the limitations of model evaluation in regression analysis.</p></li>
<li><p><strong>Simplicity Preference</strong>: Favoring simpler models with fewer predictors can lead to better generalization and reduced risk of overfitting, aligning with the principle of Occam’s Razor in statistical modeling.</p></li>
</ul>
</section>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="validation-and-cross-validation" class="level1" data-background-color="#cfb991">
<h1 data-background-color="#cfb991">Validation and Cross-Validation</h1>
<section id="validation-and-cross-validation-1" class="level2">
<h2 class="anchored" data-anchor-id="validation-and-cross-validation-1">Validation and Cross-Validation</h2>
<ul>
<li><p>Each of the procedures returns a sequence of models <span class="math inline">\(\mathcal{M}_k\)</span> indexed by model size <span class="math inline">\(k = 0, 1, 2, \ldots\)</span>. Our job here is to select <span class="math inline">\(\hat{k}\)</span>. Once selected, we will return model <span class="math inline">\(\mathcal{M}_{\hat{k}}\)</span>.</p></li>
<li><p>We compute the validation set error or the cross-validation error for each model <span class="math inline">\(\mathcal{M}_k\)</span> under consideration, and then select the <span class="math inline">\(k\)</span> for which the resulting estimated test error is smallest.</p></li>
<li><p><strong>This procedure has an advantage relative to AIC, BIC,</strong> <span class="math inline">\(C_p\)</span>, and adjusted <span class="math inline">\(R^2\)</span>, in that it provides a direct estimate of the test error, and <em>doesn’t require an estimate of the error variance</em> <span class="math inline">\(\sigma^2\)</span>.</p></li>
<li><p>It can also be used in a wider range of model selection tasks, even in cases where it is hard to pinpoint the model degrees of freedom (e.g., the number of predictors in the model) or hard to estimate the error variance <span class="math inline">\(\sigma^2\)</span>.</p></li>
</ul>
</section>
<section id="credit-data-example-1" class="level2">
<h2 class="anchored" data-anchor-id="credit-data-example-1">Credit data example</h2>
<div style="font-size: 60%;">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figs/6_3-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:65.0%"></p>
</figure>
</div>
</div>
</div>
<ul>
<li><p>The validation errors were calculated by randomly selecting three-quarters of the observations as the training set, and the remainder as the validation set.</p></li>
<li><p>The cross-validation errors were computed using <span class="math inline">\(k = 10\)</span> folds. In this case, the validation and cross-validation methods both result in a six-variable model.</p></li>
<li><p>However, all three approaches suggest that the four-, five-, and six-variable models are roughly equivalent in terms of their test errors.</p></li>
<li><p>In this setting, we can select a model using the <em>one-standard-error rule</em>.</p>
<ol type="1">
<li><strong>Estimate Test Error:</strong> We compute the test error (e.g., MSE) for each model size.</li>
<li><strong>Calculate Standard Error:</strong> Compute the standard error (SE) of the test error for each model size to account for variability.</li>
<li><strong>Select the Model:</strong> Identify the model with the <strong>lowest test error</strong> (the “best” model). Choose the <strong>simplest model</strong> whose test error is within <strong>one SE</strong> of the lowest test error.</li>
</ol></li>
</ul>
</div>
</section>
<section id="summary-validation-and-cross-validation" class="level2">
<h2 class="anchored" data-anchor-id="summary-validation-and-cross-validation">Summary: Validation and Cross-validation</h2>
<div class="nonincremental">
<div style="font-size: 60%;">
<p>Validation and cross-validation help select the best model size by estimating prediction error without needing sigma squared or the number of parameters.</p>
<div class="columns">
<div class="column" style="width:45%;">
<section id="highlights-3" class="level3">
<h3 class="anchored" data-anchor-id="highlights-3"><strong>Highlights</strong></h3>
<ul>
<li>Validation splits data into training and validation sets for error estimation.</li>
<li>Cross-validation trains on multiple parts of data to improve error estimates.</li>
<li>Choosing the optimal model size minimizes validation error effectively.</li>
<li>Avoiding sigma squared estimation is crucial in high-dimensional data scenarios.</li>
<li>The one standard error rule favors simpler models that perform similarly to the best.</li>
<li>BIC tends to prefer smaller models compared to AIC in error estimation.</li>
<li>New data challenges continuously evolve statistical methods and research.</li>
</ul>
</section>
</div><div class="column" style="width:55%;">
<section id="key-insights-3" class="level3">
<h3 class="anchored" data-anchor-id="key-insights-3"><strong>Key Insights</strong></h3>
<ul>
<li><p><strong>Model Selection</strong>: Validation and cross-validation provide direct methods for estimating prediction error, making them essential for model selection. This ensures the chosen model performs well on unseen data.</p></li>
<li><p><strong>Error Estimation</strong>: By dividing data into training and validation sets, we can effectively estimate how well a model will generalize, leading to more robust predictions in practice.</p></li>
<li><p><strong>Avoiding Estimation Challenges</strong>: In high-dimensional settings, traditional methods for estimating sigma squared and the number of parameters (<span class="math inline">\(d\)</span>) can be unreliable. Cross-validation mitigates these concerns, simplifying the model selection process.</p></li>
<li><p><strong>Simplicity Preference</strong>: The one standard error rule encourages selecting simpler models that perform nearly as well as the best, enhancing interpretability and reducing overfitting.</p></li>
<li><p><strong>Iterative Evaluation</strong>: Cross-validation’s iterative nature allows for more reliable error estimates by using multiple data partitions, thus improving the stability of model evaluations.</p></li>
<li><p><strong>BIC vs.&nbsp;AIC</strong>: BIC’s stronger penalty for model complexity often results in smaller models compared to AIC, which can lead to different model selection outcomes.</p></li>
<li><p><strong>Evolving Challenges</strong>: The increasing complexity of data in fields like high-dimensional statistics presents ongoing challenges, propelling research and innovation in statistical methodologies.</p></li>
</ul>
</section>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="shrinkage-methods" class="level1" data-background-color="#cfb991">
<h1 data-background-color="#cfb991">Shrinkage Methods</h1>
<section id="shrinkage-methods-1" class="level2">
<h2 class="anchored" data-anchor-id="shrinkage-methods-1">Shrinkage Methods</h2>
<ul>
<li><p>The subset selection methods use <em>least squares</em> to fit a linear model that contains a subset of the predictors.</p></li>
<li><p>As an alternative, we can fit a model containing all <span class="math inline">\(p\)</span> predictors using a technique that <em>constrains</em> or <em>regularizes</em> the coefficient estimates, or equivalently, that <em>shrinks</em> the coefficient estimates towards zero.</p></li>
<li><p>It may not be immediately obvious why such a constraint should improve the fit, but it turns out that shrinking the coefficient estimates can significantly reduce their variance.</p></li>
</ul>
</section>
</section>
<section id="ridge-regression" class="level1" data-background-color="#cfb991">
<h1 data-background-color="#cfb991">Ridge regression</h1>
<section id="ridge-regression-1" class="level2">
<h2 class="anchored" data-anchor-id="ridge-regression-1">Ridge regression</h2>
<div class="nonincremental">
<p>Recall that the least squares fitting procedure estimates <span class="math inline">\(\beta_0, \beta_1, \ldots, \beta_p\)</span> using the values that minimize</p>
<p><span class="math display">\[
    \text{RSS} = \sum_{i=1}^n \left( y_i - \beta_0 - \sum_{j=1}^p \beta_j x_{ij} \right)^2.
\]</span></p>
<ul>
<li>In contrast, the ridge regression coefficient estimates <span class="math inline">\(\hat{\beta}^R\)</span> are the values that minimize</li>
</ul>
<p><span class="math display">\[
\sum_{i=1}^n \left( y_i - \beta_0 - \sum_{j=1}^p \beta_j x_{ij} \right)^2 + \lambda \sum_{j=1}^p \beta_j^2
    = \text{RSS} + \lambda \sum_{j=1}^p \beta_j^2,
\]</span></p>
<p>where <span class="math inline">\(\lambda \geq 0\)</span> is a <em>tuning parameter</em>, to be determined separately.</p>
<ul>
<li>Shrinkage penalty: <span class="math inline">\(\lambda \sum_{j=1}^p \beta_j^2\)</span> penalizes coefficients that get too large. The model will pay a price according to the number of non-zero coefficients.</li>
</ul>
</div>
</section>
<section id="ridge-regression-2" class="level2">
<h2 class="anchored" data-anchor-id="ridge-regression-2">Ridge regression</h2>
<ul>
<li><p>As with least squares, ridge regression seeks coefficient estimates that fit the data well, by making the RSS small.</p></li>
<li><p>However, the second term, <span class="math inline">\(\lambda \sum_j \beta_j^2\)</span>, called a <em>shrinkage penalty</em>, is small when <span class="math inline">\(\beta_1, \ldots, \beta_p\)</span> are close to zero, and so it has the effect of <em>shrinking</em> the estimates of <span class="math inline">\(\beta_j\)</span> towards zero.</p></li>
<li><p>The tuning parameter <span class="math inline">\(\lambda\)</span> serves to control the relative impact of these two terms on the regression coefficient estimates.</p></li>
<li><p>Selecting a good value for <span class="math inline">\(\lambda\)</span> is critical; cross-validation is used for this.</p></li>
</ul>
</section>
<section id="credit-data-example-2" class="level2">
<h2 class="anchored" data-anchor-id="credit-data-example-2">Credit data example</h2>
<div style="font-size: 70%;">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figs/6_4-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:65.0%"></p>
</figure>
</div>
</div>
</div>
<ul>
<li><p>In the left-hand panel, each curve corresponds to the ridge regression coefficient estimate for one of the ten variables, plotted as a function of <span class="math inline">\(\lambda\)</span>. As <span class="math inline">\(\lambda\)</span> increases, it pushes the coefficients towards zero.</p></li>
<li><p>The right-hand panel displays the same ridge coefficient estimates as the left-hand panel, but instead of displaying <span class="math inline">\(\lambda\)</span> on the <span class="math inline">\(x\)</span>-axis, we now display <span class="math inline">\(\|\hat{\beta}_\lambda^R\|_2 / \|\hat{\beta}\|_2\)</span>, where <span class="math inline">\(\hat{\beta}\)</span> denotes the vector of least squares coefficient estimates.</p></li>
<li><p>The notation <span class="math inline">\(\|\beta\|_2\)</span> denotes the <span class="math inline">\(\ell_2\)</span> norm (pronounced “ell 2”) of a vector, and is defined as <span class="math inline">\(\|\beta\|_2 = \sqrt{\sum_{j=1}^p \beta_j^2}\)</span>.</p></li>
<li><p>In the right-hand panel, when <span class="math inline">\(\|\hat{\beta}_\lambda^R\|_2 / \|\hat{\beta}\|_2 = 1\)</span>, <span class="math inline">\(\lambda = 0\)</span>.</p></li>
</ul>
</div>
</section>
<section id="ridge-regression-scaling-of-predictors" class="level2">
<h2 class="anchored" data-anchor-id="ridge-regression-scaling-of-predictors">Ridge Regression: Scaling of Predictors</h2>
<ul>
<li><p>The standard least squares coefficient estimates are <em>scale equivariant</em>: multiplying <span class="math inline">\(X_j\)</span> by a constant <span class="math inline">\(c\)</span> simply leads to a scaling of the least squares coefficient estimates by a factor of <span class="math inline">\(1/c\)</span>. In other words, regardless of how the <span class="math inline">\(j\)</span>th predictor is scaled, <span class="math inline">\(X_j \hat{\beta}_j\)</span> will remain the same.</p></li>
<li><p>In contrast, the ridge regression coefficient estimates can change <em>substantially</em> when multiplying a given predictor by a constant, due to the sum of squared coefficients term in the penalty part of the ridge regression objective function.</p></li>
<li><p>Therefore, <strong>it is best to apply ridge regression after standardizing the predictors</strong>, using the formula</p></li>
</ul>
<div class="fragment">
<p><span class="math display">\[
\tilde{x}_{ij} = \frac{x_{ij}}{\sqrt{\frac{1}{n} \sum_{i=1}^n (x_{ij} - \bar{x}_j)^2}}
\]</span></p>
</div>
<ul>
<li>After <em>standardizing the predictors</em>, their standard deviations will be 1. That make the features comparable and make the coefficients comparable.</li>
</ul>
</section>
<section id="why-does-ridge-regression-improve-over-least-squares" class="level2">
<h2 class="anchored" data-anchor-id="why-does-ridge-regression-improve-over-least-squares">Why Does Ridge Regression Improve Over Least Squares?</h2>
<p><strong>The Bias-Variance Tradeoff</strong></p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figs/6_5-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:65.0%"></p>
</figure>
</div>
</div>
</div>
<ul>
<li><p>Simulated data with <span class="math inline">\(n = 50\)</span> observations, <span class="math inline">\(p = 45\)</span> predictors, all having nonzero coefficients.</p></li>
<li><p>Squared bias (black), variance (green), and test mean squared error (purple) for the ridge regression predictions on a simulated data set, as a function of <span class="math inline">\(\lambda\)</span> and <span class="math inline">\(\|\hat{\beta}_\lambda^R\|_2 / \|\hat{\beta}\|_2\)</span>.</p></li>
<li><p>The horizontal dashed lines indicate the minimum possible MSE. The purple crosses indicate the ridge regression models for which the MSE is smallest.</p></li>
</ul>
</section>
<section id="summary-shrinkage-methods" class="level2">
<h2 class="anchored" data-anchor-id="summary-shrinkage-methods">Summary: Shrinkage methods</h2>
<div class="nonincremental">
<div style="font-size: 60%;">
<p>Shrinkage methods like Ridge regression and Lasso use penalties to shrink coefficients towards zero, improving model performance, especially with large datasets.</p>
<div class="columns">
<div class="column" style="width:45%;">
<section id="highlights-4" class="level3">
<h3 class="anchored" data-anchor-id="highlights-4"><strong>Highlights</strong></h3>
<ul>
<li>Ridge regression uses a penalty to shrink coefficients towards zero.</li>
<li>Lasso also shrinks coefficients but can set some to exactly zero.</li>
<li>These methods are effective for large datasets with many variables.</li>
<li>Fast computation has revived interest in these techniques recently.</li>
<li>Cross-validation is crucial for selecting the optimal tuning parameter, Lambda.</li>
<li>Scaling of variables is important when applying Ridge regression.</li>
<li>Ridge regression reduces variance while maintaining bias, leading to better mean squared error.</li>
</ul>
</section>
</div><div class="column" style="width:55%;">
<section id="key-insights-4" class="level3">
<h3 class="anchored" data-anchor-id="key-insights-4"><strong>Key Insights</strong></h3>
<ul>
<li><p><strong>Shrinkage Techniques</strong>: Ridge regression and Lasso are modern approaches to regularization, balancing model fit and complexity. Shrinking coefficients helps mitigate overfitting, particularly in high-dimensional data.</p></li>
<li><p><strong>Tuning Parameter Lambda</strong>: The choice of Lambda is critical; it determines the strength of the penalty. Using cross-validation to optimize this parameter is essential for achieving the best model performance.</p></li>
<li><p><strong>Bias-Variance Tradeoff</strong>: Ridge regression effectively controls variance without significantly increasing bias, thereby minimizing mean squared error. This tradeoff is vital for model accuracy.</p></li>
<li><p><strong>Large Datasets</strong>: As datasets grow in size and complexity, shrinkage methods become increasingly relevant. They are designed to handle situations where the number of predictors can exceed the number of observations.</p></li>
<li><p><strong>Importance of Scaling</strong>: Unlike least squares, the performance of Ridge regression is sensitive to the scale of the predictors. Standardizing variables ensures comparability and effectiveness of the shrinkage.</p></li>
<li><p><strong>Continuous Shrinkage</strong>: Ridge regression produces coefficients that are close to zero but rarely exactly zero, which differs from Lasso. This characteristic can be advantageous for retaining all predictors in the model.</p></li>
<li><p><strong>Current Research Trends</strong>: Shrinkage methods are a hot topic in statistical research, with ongoing developments aimed at enhancing their effectiveness and applicability across various fields.</p></li>
</ul>
</section>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="the-lasso" class="level1" data-background-color="#cfb991">
<h1 data-background-color="#cfb991">The Lasso</h1>
<section id="the-lasso-1" class="level2">
<h2 class="anchored" data-anchor-id="the-lasso-1">The Lasso</h2>
<div class="nonincremental">
<div style="font-size: 80%;">
<ul>
<li><p>Ridge regression does have one obvious disadvantage: unlike subset selection, which will generally select models that involve just a subset of the variables, ridge regression will include all <span class="math inline">\(p\)</span> predictors in the final model.</p></li>
<li><p>The <em>Lasso</em>, first published in 1996 by Rob Tibshirani, one of the authors of the book, is an alternative to ridge regression that overcomes this disadvantage. The lasso coefficients, <span class="math inline">\(\hat{\beta}^L_\lambda\)</span>, minimize the quantity</p></li>
</ul>
<p><span class="math display">\[
  \sum_{i=1}^n \left( y_i - \beta_0 - \sum_{j=1}^p \beta_j x_{ij} \right)^2 + \lambda \sum_{j=1}^p |\beta_j| = RSS + \lambda \sum_{j=1}^p |\beta_j|.
\]</span></p>
<ul>
<li>In statistical parlance, the lasso uses the sum of absolute values, an <span class="math inline">\(\ell_1\)</span> (pronounced “ell 1”) penalty, instead of an <span class="math inline">\(\ell_2\)</span> penalty. The <span class="math inline">\(\ell_1\)</span> norm of a coefficient vector <span class="math inline">\(\beta\)</span> is given by <span class="math inline">\(\|\beta\|_1 = \sum |\beta_j|\)</span>.</li>
</ul>
</div>
</div>
</section>
<section id="the-lasso-2" class="level2">
<h2 class="anchored" data-anchor-id="the-lasso-2">The Lasso</h2>
<ul>
<li><p>As with ridge regression, the lasso shrinks the coefficient estimates towards zero.</p></li>
<li><p>However, in the case of the lasso, the <span class="math inline">\(\ell_1\)</span> penalty has the effect of forcing some of the coefficient estimates to be exactly equal to zero when the tuning parameter <span class="math inline">\(\lambda\)</span> is sufficiently large.</p></li>
<li><p>Hence, much like best subset selection, the lasso performs <em>variable selection</em>. It is a combination of shirinkage and selection of variables.</p></li>
<li><p>We say that the lasso yields <em>sparse</em> models — that is, models that involve only a subset of the variables.</p></li>
<li><p>As in ridge regression, selecting a good value of <span class="math inline">\(\lambda\)</span> for the lasso is critical; cross-validation is again the method of choice.</p></li>
</ul>
</section>
<section id="example-credit-dataset" class="level2">
<h2 class="anchored" data-anchor-id="example-credit-dataset">Example: Credit Dataset</h2>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figs/6_6-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:65.0%"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="the-variable-selection-property-of-the-lasso" class="level2">
<h2 class="anchored" data-anchor-id="the-variable-selection-property-of-the-lasso">The Variable Selection Property of the Lasso</h2>
<p>Why is it that the lasso, unlike ridge regression, results in coefficient estimates that are exactly equal to zero?</p>
<p>One can show that the lasso and ridge regression coefficient estimates solve the problems (equivalent to Lagrange formulations):</p>
<p><span class="math display">\[
\text{minimize}_{\beta} \sum_{i=1}^{n} \left( y_i - \beta_0 - \sum_{j=1}^{p} \beta_j x_{ij} \right)^2 \quad \text{subject to} \quad \sum_{j=1}^{p} |\beta_j| \leq s
\]</span></p>
<p>and</p>
<p><span class="math display">\[
\text{minimize}_{\beta} \sum_{i=1}^{n} \left( y_i - \beta_0 - \sum_{j=1}^{p} \beta_j x_{ij} \right)^2 \quad \text{subject to} \quad \sum_{j=1}^{p} \beta_j^2 \leq s,
\]</span></p>
<p>respectively.</p>
</section>
<section id="the-lasso-and-ridge-picture" class="level2">
<h2 class="anchored" data-anchor-id="the-lasso-and-ridge-picture">The Lasso and Ridge Picture</h2>
<p>This picture helps to explain why the lasso gives sparsity:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figs/6_7-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:65.0%"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>On the right we have the ridge regression and on the left is the lasso regression.</li>
<li>It is possible to see where the where the red boundary touch the blue constraing.</li>
<li>In the case of the ridge regression (right plot), we see that the solution does not create a zero.</li>
<li>In the case of the lasso regression (left plot), we see that the solution does create a zero for one of the predictors.</li>
</ul>
</section>
<section id="comparing-the-lasso-and-ridge-regression" class="level2">
<h2 class="anchored" data-anchor-id="comparing-the-lasso-and-ridge-regression">Comparing the Lasso and Ridge Regression</h2>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figs/6_8-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:65.0%"></p>
</figure>
</div>
</div>
</div>
<p>Simulated data with <span class="math inline">\(n = 50\)</span> observations, <span class="math inline">\(p = 45\)</span> predictors, all having nonzero coefficients.</p>
<p><strong>Left:</strong> Lasso: Plots of squared bias (black), variance (green), and test MSE (purple) for the lasso on simulated data set.</p>
<p><strong>Right:</strong> Comparison of squared bias, variance, and test MSE between lasso (solid) and ridge (dashed). Both are plotted against their <span class="math inline">\(R^2\)</span> on the training data, as a common form of indexing. The crosses in both plots indicate the lasso model for which the MSE is smallest.</p>
</section>
<section id="comparing-the-lasso-and-ridge-regression-continued" class="level2">
<h2 class="anchored" data-anchor-id="comparing-the-lasso-and-ridge-regression-continued">Comparing the Lasso and Ridge Regression: continued</h2>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figs/6_9-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:65.0%"></p>
</figure>
</div>
</div>
</div>
<p><strong>Left:</strong> Plots of squared bias (black), variance (green), and test MSE (purple) for the lasso. The simulated data equals to the one used before, except that now only two predictors are related to the response.</p>
<p><strong>Right:</strong> Comparison of squared bias, variance, and test MSE between lasso (solid) and ridge (dashed). Both are plotted against their <span class="math inline">\(R^2\)</span> on the training data, as a common form of indexing. The crosses in both plots indicate the lasso model for which the MSE is smallest.</p>
</section>
<section id="conclusions-about-ridge-and-lasso" class="level2">
<h2 class="anchored" data-anchor-id="conclusions-about-ridge-and-lasso">Conclusions about Ridge and Lasso</h2>
<ul>
<li><p>These two examples illustrate that neither ridge regression nor the lasso will universally dominate the other.</p></li>
<li><p>In general, one might expect the lasso to perform better when the response is a function of only a relatively small number of predictors.</p></li>
<li><p>However, the number of predictors that is related to the response is never known <em>a priori</em> for real data sets.</p></li>
<li><p>A technique such as cross-validation can be used in order to determine which approach is better on a particular data set.</p></li>
</ul>
</section>
<section id="summary-lasso" class="level2">
<h2 class="anchored" data-anchor-id="summary-lasso">Summary: Lasso</h2>
<div class="nonincremental">
<div style="font-size: 60%;">
<p>The Lasso regression technique improves upon ridge regression by both shrinking coefficients and performing variable selection, setting some coefficients to zero.</p>
<div class="columns">
<div class="column" style="width:45%;">
<section id="highlights-5" class="level3">
<h3 class="anchored" data-anchor-id="highlights-5"><strong>Highlights</strong></h3>
<ul>
<li>Lasso regression shrinks coefficients while allowing for variable selection.</li>
<li>It uses an <span class="math inline">\(L_1\)</span> penalty, contrasting with ridge’s <span class="math inline">\(L_2\)</span> penalty.</li>
<li>The concept of sparsity is central to Lasso’s effectiveness.</li>
<li>Increased computational efficiency has popularized Lasso in recent years.</li>
<li>Lasso is particularly useful in high-dimensional datasets with many features.</li>
<li>Cross-validation is essential for selecting the optimal lambda value.</li>
<li>Performance varies: Lasso excels in sparse models, while ridge may perform better in dense ones.</li>
</ul>
</section>
</div><div class="column" style="width:55%;">
<section id="key-insights-5" class="level3">
<h3 class="anchored" data-anchor-id="key-insights-5"><strong>Key Insights</strong></h3>
<ul>
<li><p><strong>Lasso vs.&nbsp;Ridge</strong>: Lasso regression not only shrinks coefficients but also sets some to zero, enabling simpler models through variable selection. This property makes it particularly valuable in high-dimensional settings where many variables may be irrelevant.</p></li>
<li><p><span class="math inline">\(L_1\)</span> vs.&nbsp;<span class="math inline">\(L_2\)</span> Penalty: The <span class="math inline">\(L_1\)</span> penalty used in Lasso creates a constraint that promotes sparsity, while the <span class="math inline">\(L_2\)</span> penalty in ridge regression tends to retain all variables with smaller coefficients. This difference is crucial for effective model building.</p></li>
<li><p><strong>Sparsity</strong>: The concept of sparsity refers to models that only include a small subset of variables. Sparse models are easier to interpret and can enhance predictive performance when only a few predictors are relevant.</p></li>
<li><p><strong>Computational Advances</strong>: Recent improvements in computational power and techniques in convex optimization have made applying Lasso feasible even on large datasets, broadening its applicability across various fields.</p></li>
<li><p><strong>Real-World Applications</strong>: In situations like medical diagnostics, where finding a minimal number of significant predictors is vital, Lasso provides a practical solution by efficiently identifying key variables among thousands of measurements.</p></li>
<li><p><strong>Choosing Lambda</strong>: The tuning parameter lambda is critical; cross-validation is typically used to determine its optimal value, balancing model complexity and predictive accuracy.</p></li>
<li><p><strong>Model Performance</strong>: The effectiveness of Lasso and ridge regression varies based on the underlying data structure. Lasso performs better with sparse true models, while ridge regression may be more effective when many predictors are significant.</p></li>
</ul>
</section>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="selecting-the-tuning-parameter-for-ridge-regression-and-lasso" class="level1" data-background-color="#cfb991">
<h1 data-background-color="#cfb991">Selecting the Tuning Parameter for Ridge Regression and Lasso</h1>
<section id="selecting-the-tuning-parameter-for-ridge-regression-and-lasso-1" class="level2">
<h2 class="anchored" data-anchor-id="selecting-the-tuning-parameter-for-ridge-regression-and-lasso-1">Selecting the Tuning Parameter for Ridge Regression and Lasso</h2>
<ul>
<li>As for subset selection, for ridge regression and lasso we require a method to determine which of the models under consideration is best.</li>
<li>That is, we require a method selecting a value for the tuning parameter <span class="math inline">\(\lambda\)</span> or equivalently, the value of the constraint <span class="math inline">\(s\)</span>.</li>
<li><em>Cross-validation</em> provides a simple way to tackle this problem. We choose a grid of <span class="math inline">\(\lambda\)</span> values, and compute the cross-validation error rate for each value of <span class="math inline">\(\lambda\)</span>.</li>
<li>We then select the tuning parameter value for which the cross-validation error is smallest.</li>
<li>Finally, the model is re-fit using all of the available observations and the selected value of the tuning parameter.</li>
</ul>
</section>
<section id="credit-data-example-3" class="level2">
<h2 class="anchored" data-anchor-id="credit-data-example-3">Credit data example</h2>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figs/6_12-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:65.0%"></p>
</figure>
</div>
</div>
</div>
<p><strong>Left:</strong> Cross-validation errors that result from applying ridge regression to the <em>Credit</em> data set with various values of <span class="math inline">\(\lambda\)</span>. <span class="math inline">\(\lambda = 0.05\)</span> minimizes the cross-validation error.</p>
<p><strong>Right:</strong> The coefficient estimates as a function of <span class="math inline">\(\lambda\)</span>. The vertical dashed line indicates the value of <span class="math inline">\(\lambda\)</span> selected by cross-validation.</p>
</section>
<section id="simulated-data-example" class="level2">
<h2 class="anchored" data-anchor-id="simulated-data-example">Simulated Data Example</h2>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figs/6_13-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:65.0%"></p>
</figure>
</div>
</div>
</div>
<p><strong>Left:</strong> Ten-fold cross-validation MSE for the lasso, applied to the sparse simulated data set.</p>
<p><strong>Right:</strong> The corresponding lasso coeﬃcient estimates are displayed. The vertical dashed lines indicate the lasso fit for which the cross-validation error is smallest.</p>
</section>
<section id="summary-selecting-the-tuning-parameter-lambda" class="level2">
<h2 class="anchored" data-anchor-id="summary-selecting-the-tuning-parameter-lambda">Summary: Selecting the tuning parameter (lambda)</h2>
<div class="nonincremental">
<div style="font-size: 60%;">
<p>Selecting the tuning parameter (lambda) for ridge regression and lasso is crucial, as it significantly influences model performance. Cross-validation is an effective method for this selection.</p>
<div class="columns">
<div class="column" style="width:45%;">
<section id="highlights-6" class="level3">
<h3 class="anchored" data-anchor-id="highlights-6"><strong>Highlights</strong></h3>
<ul>
<li>Lambda is crucial: Affects the solution from full least squares to zero coefficients.</li>
<li>⚖️ Regularization importance: Zero lambda means no regularization; high lambda leads to zero solutions.</li>
<li>Cross-validation advantage: Ideal for tuning parameters as it doesn’t require the unknown number of parameters (<span class="math inline">\(d\)</span>).</li>
<li>Ridge example: With lambda of 100, all variables appear included, but coefficients are shrunk.</li>
<li>Cross-validation curves: Show how errors change with varying lambda values for both ridge and lasso.</li>
<li>Lasso effectiveness: Properly identifies non-zero coefficients while setting others to zero.</li>
<li>Simulation success: In a simulated scenario, the model accurately identifies the correct number of non-zero coefficients.</li>
</ul>
</section>
</div><div class="column" style="width:55%;">
<section id="key-insights-6" class="level3">
<h3 class="anchored" data-anchor-id="key-insights-6"><strong>Key Insights</strong></h3>
<ul>
<li><p><strong>Importance of Lambda</strong>: The tuning parameter lambda significantly influences the model’s complexity and overall performance. Choosing lambda wisely is essential for achieving the desired balance between bias and variance.</p></li>
<li><p><strong>Cross-validation as a solution</strong>: Cross-validation provides a robust framework for assessing model performance across different lambda values without needing to know the exact number of parameters, making it a practical choice for tuning.</p></li>
<li><p><strong>Degree of freedom confusion</strong>: In ridge regression, even when coefficients are shrunk, counting parameters can be misleading, as all variables remain included in the model.</p></li>
<li><p><strong>Regularization trade-offs</strong>: The process of regularization through ridge and lasso not only simplifies models but also introduces nuanced definitions of model complexity, changing our understanding of ‘degrees of freedom.’</p></li>
<li><p><strong>Error analysis via curves</strong>: Cross-validation curves reveal how model errors fluctuate with lambda, helping visualize optimal tuning points.</p></li>
<li><p><strong>Lasso’s precision</strong>: Lasso regression demonstrates its strength in feature selection, effectively pinpointing relevant variables while ignoring the irrelevant ones, enhancing interpretability.</p></li>
</ul>
</section>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="dimension-reduction-methods" class="level1" data-background-color="#cfb991">
<h1 data-background-color="#cfb991">Dimension Reduction Methods</h1>
<section id="dimension-reduction-methods-1" class="level2">
<h2 class="anchored" data-anchor-id="dimension-reduction-methods-1">Dimension Reduction Methods</h2>
<ul>
<li><p>The methods that we have discussed so far have involved fitting linear regression models, via least squares or a shrunken approach, using the original predictors, <span class="math inline">\(X_1, X_2, \ldots, X_p\)</span>.</p></li>
<li><p>We now explore a class of approaches that <em>transform</em> the predictors and then fit a least squares model using the transformed variables. We will refer to these techniques as <em>dimension reduction</em> methods.</p></li>
</ul>
</section>
<section id="dimension-reduction-methods-details" class="level2">
<h2 class="anchored" data-anchor-id="dimension-reduction-methods-details">Dimension Reduction Methods: Details</h2>
<div class="nonincremental">
<div style="font-size: 80%;">
<ul>
<li>Let <span class="math inline">\(Z_1, Z_2, \ldots, Z_M\)</span> represent <span class="math inline">\(M &lt; p\)</span> <em>linear combinations</em> of our original <span class="math inline">\(p\)</span> predictors. That is,</li>
</ul>
<p><span class="math display">\[
    Z_m = \sum_{j=1}^p \phi_{mj} X_j \quad \text{(1)}
\]</span></p>
<p>for some constants <span class="math inline">\(\phi_{m1}, \ldots, \phi_{mp}\)</span>.</p>
<ul>
<li>We can then fit the linear regression model,</li>
</ul>
<p><span class="math display">\[
    y_i = \theta_0 + \sum_{m=1}^M \theta_m z_{im} + \epsilon_i, \quad i = 1, \ldots, n, \quad \text{(2)}
\]</span></p>
<p>using ordinary least squares.</p>
<ul>
<li>Note that in model (2), the regression coefficients are given by <span class="math inline">\(\theta_0, \theta_1, \ldots, \theta_M\)</span>. If the constants <span class="math inline">\(\phi_{m1}, \ldots, \phi_{mp}\)</span> are chosen wisely, then such dimension reduction approaches can often outperform OLS regression.</li>
</ul>
</div>
</div>
</section>
<section id="dimension-reduction-methods-2" class="level2">
<h2 class="anchored" data-anchor-id="dimension-reduction-methods-2">Dimension Reduction Methods</h2>
<div class="nonincremental">
<div style="font-size: 80%;">
<ul>
<li>Notice that from definition (1),</li>
</ul>
<p><span class="math display">\[
    \sum_{m=1}^M \theta_m z_{im} = \sum_{m=1}^M \theta_m \sum_{j=1}^p \phi_{mj} x_{ij} = \sum_{j=1}^p \sum_{m=1}^M \theta_m \phi_{mj} x_{ij} = \sum_{j=1}^p \beta_j x_{ij},
\]</span> where</p>
<p><span class="math display">\[
    \beta_j = \sum_{m=1}^M \theta_m \phi_{mj}. \quad \text{(3)}
\]</span></p>
<ul>
<li><p>Hence model (2) can be thought of as a special case of the original linear regression model.</p></li>
<li><p>Dimension reduction serves to constrain the estimated <span class="math inline">\(\beta_j\)</span> coefficients, since now they must take the form (3).</p></li>
<li><p>Can win in the bias-variance tradeoff.</p></li>
</ul>
</div>
</div>
</section>
<section id="summary-dimension-reduction" class="level2">
<h2 class="anchored" data-anchor-id="summary-dimension-reduction">Summary: Dimension reduction</h2>
<div class="nonincremental">
<div style="font-size: 60%;">
<p>Dimension reduction transforms original predictors into fewer linear combinations, improving model fitting while maintaining low bias and variance.</p>
<div class="columns">
<div class="column" style="width:45%;">
<section id="highlights-7" class="level3">
<h3 class="anchored" data-anchor-id="highlights-7"><strong>Highlights</strong></h3>
<ul>
<li>Dimension Reduction simplifies models by using fewer predictors.</li>
<li>New predictors are linear combinations of original ones.</li>
<li>Fitting uses least squares on transformed predictors.</li>
<li>Aim: Reduce dimensions from <span class="math inline">\(P\)</span> predictors to <span class="math inline">\(M\)</span> (<span class="math inline">\(M &lt; P\)</span>).</li>
<li>Balances bias and variance effectively.</li>
<li>Similar to Ridge and Lasso, but with different coefficient constraints.</li>
<li>Works best when <span class="math inline">\(M &lt; P\)</span>; otherwise, it results in standard least squares.</li>
</ul>
</section>
</div><div class="column" style="width:55%;">
<section id="key-insights-7" class="level3">
<h3 class="anchored" data-anchor-id="key-insights-7"><strong>Key Insights</strong></h3>
<ul>
<li><p><strong>Efficiency in Modeling</strong>: Dimension reduction allows for a simpler model with fewer predictors, leading to potentially better performance without losing significant information. This method is advantageous in high-dimensional datasets.</p></li>
<li><p><strong>Construction of New Predictors</strong>: By creating new predictors through linear combinations, we can capture essential relationships in the data while reducing complexity, which may help in enhancing interpretability.</p></li>
<li><p><strong>Bias-Variance Trade-off</strong>: This approach effectively manages the bias-variance trade-off, leading to models with lower bias and variance compared to using all original features, which is crucial for better generalization to unseen data.</p></li>
<li><p><strong>Use of Least Squares</strong>: While retaining the least squares fitting method, this approach modifies the predictor space, allowing for a fresh perspective on regression problems and leading to potentially improved outcomes.</p></li>
<li><p><strong>Relation to Ridge and Lasso</strong>: Although dimension reduction shares similarities with Ridge and Lasso in terms of model fitting, it introduces unique constraints on coefficients, which can lead to different insights about the data.</p></li>
<li><p><strong>Importance of Dimensions</strong>: The effectiveness of dimension reduction hinges on the condition that <span class="math inline">\(M\)</span> (new predictors) is less than <span class="math inline">\(P\)</span> (original predictors). If <span class="math inline">\(M = P\)</span>, the method reduces to standard least squares, negating its advantages.</p></li>
<li><p><strong>Innovation in Coefficient Form</strong>: The requirement for coefficients to adopt a specific structure in dimension reduction can provide insights into the relationships among predictors, enhancing model interpretability and utility.</p></li>
</ul>
</section>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="principal-components-regression" class="level1" data-background-color="#cfb991">
<h1 data-background-color="#cfb991">Principal Components Regression</h1>
<section id="principal-components-regression-1" class="level2">
<h2 class="anchored" data-anchor-id="principal-components-regression-1">Principal Components Regression</h2>
<ul>
<li><p>By far the most famous dimension reduction approach. It involves a two-step procedure:</p>
<ul>
<li>Step 1: we find what are called principal components of the data matrix (linear combinations of the predictors)</li>
<li>Step 2: we perform least squares regression using those principal components as predictors</li>
</ul></li>
<li><p>The first principal component is that (normalized) linear combination of the variables with the largest variance.</p></li>
<li><p>The second principal component has the largest variance, subject to being uncorrelated with the first.</p></li>
<li><p>And so on.</p></li>
<li><p>Hence with many correlated original variables, we replace them with a small set of principal components that capture their joint variation.</p></li>
<li><p>The intuition is that if you have a data set with 45 variables and compute a few principal components, those might capture most of the variation in the data.</p></li>
</ul>
</section>
<section id="pictures-of-pca" class="level2">
<h2 class="anchored" data-anchor-id="pictures-of-pca">Pictures of PCA</h2>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figs/6_14-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:65.0%"></p>
</figure>
</div>
</div>
</div>
<p>The population size (<code>pop</code>) and ad spending (<code>ad</code>) for 100 different cities are shown as purple circles. The green solid line indicates the first principal component, and the blue dashed line indicates the second principal component.</p>
<p>Note that these two principal components are uncorrelated!</p>
</section>
<section id="pictures-of-pca-1" class="level2">
<h2 class="anchored" data-anchor-id="pictures-of-pca-1">Pictures of PCA</h2>
<div class="nonincremental">
<div style="font-size: 80%;">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figs/6_15-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:65.0%"></p>
</figure>
</div>
</div>
</div>
<p><em>A subset of the advertising data.</em></p>
<ul>
<li><p><strong>Left:</strong> The first principal component, chosen to minimize the sum of the squared perpendicular distances to each point, is shown in green. These distances are represented using the black dashed line segments.</p></li>
<li><p><strong>Right:</strong> The left-hand panel has been rotated so that the first principal component lies on the x-axis.</p></li>
</ul>
</div>
</div>
</section>
<section id="pictures-of-pca-2" class="level2">
<h2 class="anchored" data-anchor-id="pictures-of-pca-2">Pictures of PCA</h2>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figs/6_16-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:65.0%"></p>
</figure>
</div>
</div>
</div>
<div style="font-size: 60%;">
<p><em>Plots of the first principal component scores</em> <span class="math inline">\(z_{i1}\)</span> versus <strong>pop</strong> and <strong>ad</strong>. The relationships are strong.</p>
<ul>
<li><p>We can visualize each principal component by plotting it against the original variables, such as population and ad spending.</p></li>
<li><p>We observe that the first principal component is highly correlated with both population and ad spending. This indicates that the first principal component effectively captures the variability in these two variables, summarizing the data in a meaningful way.</p></li>
<li><p><strong>This suggests a valuable insight</strong>: instead of using the original variables (population and ad spending) directly, we can use the first principal component as a single, simplified predictor. We have the assumption that a linear combination of the predictors that has high variance is probably going to be associated with the response.</p>
<ul>
<li>For example, if my goal is to predict a response variable like sales, we can incorporate the first principal component as a predictor in the model. This approach reduces the dimensionality of the data while retaining much of the information, potentially improving model interpretability and efficiency.</li>
</ul></li>
</ul>
</div>
</section>
<section id="pictures-of-pca-3" class="level2">
<h2 class="anchored" data-anchor-id="pictures-of-pca-3">Pictures of PCA</h2>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figs/6_17-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:65.0%"></p>
</figure>
</div>
</div>
</div>
<p><em>Plots of the second principal component scores</em> <span class="math inline">\(z_{i2}\)</span> versus <strong>pop</strong> and <strong>ad</strong>. The relationships are weak.</p>
</section>
<section id="application-to-principal-components-regression" class="level2">
<h2 class="anchored" data-anchor-id="application-to-principal-components-regression">Application to Principal Components Regression</h2>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figs/6_18-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:65.0%"></p>
</figure>
</div>
</div>
</div>
<p><em>PCR was applied to two simulated data sets.</em> The black, green, and purple lines correspond to squared bias, variance, and test mean squared error, respectively.</p>
<ul>
<li><p>Left: Simulated data with <span class="math inline">\(n= 50\)</span> observations, <span class="math inline">\(p= 45\)</span> predictors. The plot shows that a model with <span class="math inline">\(\approx 18\)</span> principal components can provide a good result.</p></li>
<li><p>Right: Simulated data with <span class="math inline">\(n= 50\)</span> observations, <span class="math inline">\(p= 45\)</span> predictors, except that now only two predictors are related to the response. The plot shows that a model with <span class="math inline">\(\approx 25\)</span> principal components can provide a good result.</p></li>
</ul>
</section>
<section id="choosing-the-number-of-principal-component-directions-m" class="level2">
<h2 class="anchored" data-anchor-id="choosing-the-number-of-principal-component-directions-m">Choosing the Number of Principal Component Directions <span class="math inline">\(M\)</span></h2>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figs/6_20-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:65.0%"></p>
</figure>
</div>
</div>
</div>
<p><em>Left</em>: <strong>PCR standardized coefficient estimates</strong> on the <strong>Credit</strong> data set for different values of <span class="math inline">\(M\)</span>.</p>
<p><em>Right</em>: The <strong>10-fold cross-validation MSE</strong> obtained using PCR, as a function of <span class="math inline">\(M\)</span>. For each of the models we can see the cross-validated mean squared error. Here we have disappointing result. If we pick a model for which the mean squared error is as small as possible, here the mean squared error is really as small as possible when we have a model with 10 or 11 components. However, in our dataset <span class="math inline">\(M = 11\)</span> is going to be the regular least squares on the original data using all variables. Basically, principal components regression does not provide any gains in this case.</p>
</section>
</section>
<section id="partial-least-squares-pls" class="level1" data-background-color="#cfb991">
<h1 data-background-color="#cfb991">Partial Least Squares (PLS)</h1>
<section id="partial-least-squares-pls-1" class="level2">
<h2 class="anchored" data-anchor-id="partial-least-squares-pls-1">Partial Least Squares (PLS)</h2>
<ul>
<li><p><strong>PCR</strong> identifies linear combinations, or <strong>directions</strong>, that best represent the predictors <span class="math inline">\(X_1, \dots, X_p\)</span>.</p></li>
<li><p>These directions are identified in an <strong>unsupervised</strong> way, since the response <span class="math inline">\(Y\)</span> is not used to help determine the principal component directions.</p></li>
<li><p>That is, the response does not <strong>supervise</strong> the identification of the principal components.</p></li>
<li><p>Consequently, <strong>PCR</strong> suffers from a potentially serious drawback: <strong>there is no guarantee that the directions that best explain the predictors will also be the best directions to use for predicting the response</strong>.</p></li>
<li><p>A potential solution is to use Partial Least Squares (PLS).</p></li>
</ul>
</section>
<section id="partial-least-squares-pls-2" class="level2">
<h2 class="anchored" data-anchor-id="partial-least-squares-pls-2">Partial Least Squares (PLS)</h2>
<ul>
<li><p>Like <strong>PCR</strong>, <strong>PLS</strong> is a dimension reduction method, which first identifies a new set of features <span class="math inline">\(Z_1, \dots, Z_M\)</span> that are linear combinations of the original features, and then fits a linear model via <strong>OLS</strong> using these <span class="math inline">\(M\)</span> new features.</p></li>
<li><p>But unlike <strong>PCR</strong>, <strong>PLS</strong> identifies these new features in a <strong>supervised</strong> way – that is, it makes use of the response <span class="math inline">\(Y\)</span> in order to identify new features that not only approximate the old features well, but also that <em>are related to the response</em>.</p></li>
<li><p><strong>PLS</strong> approach attempts to find directions that help explain both the response and the predictors.</p></li>
</ul>
</section>
<section id="partial-least-squares-pls-details" class="level2">
<h2 class="anchored" data-anchor-id="partial-least-squares-pls-details">Partial Least Squares (PLS): Details</h2>
<ul>
<li><p>After standardizing the <span class="math inline">\(p\)</span> predictors, <strong>PLS</strong> computes the first direction <span class="math inline">\(Z_1\)</span> by setting each <span class="math inline">\(\phi_{1j}\)</span> in (1) equal to the coefficient from the simple linear regression of <span class="math inline">\(Y\)</span> onto <span class="math inline">\(X_j\)</span>.</p></li>
<li><p>One can show that this coefficient is proportional to the correlation between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X_j\)</span>.</p></li>
<li><p>Hence, in computing <span class="math inline">\(Z_1 = \sum_{j=1}^p \phi_{1j} X_j\)</span>, <strong>PLS</strong> places the highest weight on the variables that are most strongly related to the response.</p></li>
<li><p>Subsequent directions are found by taking residuals and then repeating the above prescription.</p></li>
<li><p>The authors of the book highlight that <strong>PLS</strong> does not bring to much gain when compared to Ridge regression approach, for example.</p></li>
</ul>
</section>
<section id="summary-principal-components-regression-pcr" class="level2">
<h2 class="anchored" data-anchor-id="summary-principal-components-regression-pcr">Summary: Principal Components Regression (PCR)</h2>
<div class="nonincremental">
<div style="font-size: 60%;">
<p>Principal Components Regression (PCR) reduces dimensionality by finding principal components and using them in least squares regression for efficient modeling.</p>
<div class="columns">
<div class="column" style="width:45%;">
<section id="highlights-8" class="level3">
<h3 class="anchored" data-anchor-id="highlights-8"><strong>Highlights</strong></h3>
<ul>
<li>Principal Components Regression (PCR) uses a two-step procedure to reduce dimensionality.</li>
<li>First, principal components with the highest variance are identified from the data.</li>
<li>The first principal component is aligned with the direction of maximum variance.</li>
<li>The second principal component is uncorrelated with the first and captures additional variance.</li>
<li>Using few principal components can effectively summarize complex datasets.</li>
<li>Choosing the optimal number of components is crucial for minimizing mean squared error.</li>
<li>Partial Least Squares (PLS) improves upon PCR by considering response variables in component selection.</li>
</ul>
</section>
</div><div class="column" style="width:55%;">
<section id="key-insights-8" class="level3">
<h3 class="anchored" data-anchor-id="key-insights-8"><strong>Key Insights</strong></h3>
<ul>
<li><p><strong>Dimensionality Reduction</strong>: PCR simplifies models by reducing the number of predictors while retaining essential information, aiding in interpretation and computation. This is particularly useful with datasets containing many variables relative to observations.</p></li>
<li><p><strong>Uncorrelated Components</strong>: The process ensures that the principal components are uncorrelated, which helps in creating more robust models by minimizing multicollinearity issues common in regression analysis.</p></li>
<li><p><strong>Model Selection</strong>: The selection of the number of components directly impacts model performance. Cross-validation is recommended to find the optimal number of components for the best predictive accuracy.</p></li>
<li><p><strong>Efficiency in Prediction</strong>: PCR can significantly enhance prediction accuracy when dealing with high-dimensional data by focusing on variance rather than individual variable contributions.</p></li>
<li><p><strong>Assumption of Variance-Response Relationship</strong>: The effectiveness of PCR hinges on the assumption that high variance directions in predictors correlate with the response, which may not always hold true.</p></li>
<li><p><strong>Partial Least Squares</strong>: PLS offers a supervised alternative to PCR by incorporating response variable information, potentially leading to better predictive models, although it may not always outperform PCR.</p></li>
<li><p><strong>Modern Applications</strong>: Techniques like PCR and PLS are increasingly relevant in fields with large datasets, where simpler models are needed to prevent overfitting and enhance interpretability.</p></li>
</ul>
</section>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="summary" class="level1" data-background-color="#cfb991">
<h1 data-background-color="#cfb991">Summary</h1>
<section id="summary-1" class="level2">
<h2 class="anchored" data-anchor-id="summary-1">Summary</h2>
<div class="nonincremental">
<div style="font-size: 70%;">
<div class="columns">
<div class="column" style="width:50%;">
<section id="key-concepts" class="level3">
<h3 class="anchored" data-anchor-id="key-concepts">Key Concepts</h3>
<ul>
<li><strong>Three classes of methods</strong>:
<ol type="1">
<li><strong>Subset Selection</strong>: Focuses on identifying subsets of predictors for simpler models.</li>
<li><strong>Shrinkage Methods</strong>: Regularizes coefficients to reduce variance and improve model performance (e.g., Ridge, Lasso).</li>
<li><strong>Dimension Reduction</strong>: Reduces the number of predictors using linear combinations (e.g., PCA, PLS).</li>
</ol></li>
<li><strong>Model Selection Criteria</strong>:
<ul>
<li>Use metrics like $C_p $, AIC, BIC, and Adjusted $R^2 $to balance model fit and complexity.</li>
<li><strong>Cross-validation</strong> is essential for estimating test error and selecting tuning parameters.</li>
</ul></li>
<li><strong>Bias-Variance Tradeoff</strong>:
<ul>
<li>Shrinkage methods improve prediction accuracy by reducing variance while maintaining bias.</li>
</ul></li>
</ul>
</section>
</div><div class="column" style="width:50%;">
<section id="practical-insights" class="level3">
<h3 class="anchored" data-anchor-id="practical-insights">Practical Insights</h3>
<ul>
<li><strong>Best Subset Selection</strong>:
<ul>
<li>Computationally intensive (<span class="math inline">\(2^p\)</span> models).</li>
<li>Not recommended for <span class="math inline">\(p &gt; 20\)</span>.</li>
</ul></li>
<li><strong>Stepwise Selection</strong>:
<ul>
<li>More efficient (<span class="math inline">\(p^2\)</span> models).</li>
<li>Forward and backward methods balance performance and computation.</li>
</ul></li>
<li><strong>Ridge vs.&nbsp;Lasso</strong>:
<ul>
<li>Ridge shrinks coefficients but includes all predictors.</li>
<li>Lasso performs variable selection by setting coefficients to zero.</li>
</ul></li>
<li><strong>Principal Components Regression (PCR)</strong>:
<ul>
<li>Reduces dimensionality by finding uncorrelated components.</li>
<li>Works well when high variance directions correlate with the response.</li>
</ul></li>
<li><strong>Partial Least Squares (PLS)</strong>:
<ul>
<li>Supervised alternative to PCR, incorporating response variable information.</li>
</ul></li>
</ul>
</section>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="thank-you" class="level1" data-background-color="#cfb991">
<h1 data-background-color="#cfb991">Thank you!</h1>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>